{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d32d91-6db7-40fc-a428-07d93c48b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group\n",
      "34-60    4350\n",
      "0-34     3078\n",
      "60-78    1881\n",
      "78+       219\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to map ages to custom age groups\n",
    "def map_age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "def split_data_by_age_cv(df, age_column='age', n_splits=5, random_state=42):\n",
    "    # Map each age to the custom age group\n",
    "    df['age_group'] = df[age_column].apply(map_age_to_group)\n",
    "\n",
    "    # Group the data by the custom age groups\n",
    "    age_groups = df.groupby('age_group')\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    fold_data = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_list = []\n",
    "        test_list = []\n",
    "        \n",
    "        for _, group in age_groups:\n",
    "            group_train_index = [idx for idx in train_index if idx in group.index]\n",
    "            group_test_index = [idx for idx in test_index if idx in group.index]\n",
    "            \n",
    "            train = group.loc[group_train_index]\n",
    "            test = group.loc[group_test_index]\n",
    "            \n",
    "            train_list.append(train)\n",
    "            test_list.append(test)\n",
    "        \n",
    "        train_df = pd.concat(train_list, ignore_index=True)\n",
    "        test_df = pd.concat(test_list, ignore_index=True)\n",
    "        \n",
    "        fold_data.append((train_df, test_df))\n",
    "    \n",
    "    return fold_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "imputed_data = pd.read_csv('imputed_data.csv', index_col=0)  # Replace with your actual data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fold_data = split_data_by_age_cv(imputed_data)\n",
    "\n",
    "# To verify, print the age groups in the first fold\n",
    "print(fold_data[0][0]['age_group'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc51702c-ea39-433f-bf56-e3bf5e05afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the imputed data\n",
    "imputed_data = pd.read_csv('imputed_data.csv', index_col=0)\n",
    "\n",
    "# Define function to map ages to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Apply the function to create age groups\n",
    "imputed_data['age_group'] = imputed_data['age'].apply(age_to_group)\n",
    "\n",
    "# Define function to select top 30 features based on Pearson correlation with age\n",
    "def select_top_features(data, age_column='age', top_n=30):\n",
    "    # Ensure only numeric columns are used for correlation calculation\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    \n",
    "    correlations = numeric_data.corr()[age_column].abs().sort_values(ascending=False)\n",
    "    top_features = correlations.index[1:top_n+1].tolist()  # Exclude the age column itself\n",
    "    return top_features\n",
    "\n",
    "# Directory to save the top features\n",
    "top_features_dir = '.'\n",
    "os.makedirs(top_features_dir, exist_ok=True)\n",
    "\n",
    "# Select and save top 30 features for each age group\n",
    "age_groups = imputed_data['age_group'].unique()\n",
    "\n",
    "top_30_features_all_age_group = {}\n",
    "\n",
    "for age_group in age_groups:\n",
    "    group_data = imputed_data[imputed_data['age_group'] == age_group]\n",
    "    \n",
    "    # Select top 30 features for the current age group\n",
    "    top_features = select_top_features(group_data)\n",
    "    top_30_features_all_age_group[age_group] = top_features\n",
    "    \n",
    "    # Save top features to a CSV file\n",
    "    top_features_df = pd.DataFrame(top_features, columns=[f'Top 30 Features for Age Group {age_group}'])\n",
    "\n",
    "\n",
    "# Save all top features to a single CSV file\n",
    "top_30_features_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in top_30_features_all_age_group.items()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5617659d-342a-4151-b1ab-05cd304337b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-34</th>\n",
       "      <th>60-78</th>\n",
       "      <th>34-60</th>\n",
       "      <th>78+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cg16867657</td>\n",
       "      <td>cg16867657</td>\n",
       "      <td>cg16867657</td>\n",
       "      <td>cg14571574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cg05412028</td>\n",
       "      <td>cg22454769</td>\n",
       "      <td>cg22454769</td>\n",
       "      <td>cg24273318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cg19283806</td>\n",
       "      <td>cg21572722</td>\n",
       "      <td>cg19283806</td>\n",
       "      <td>cg01763090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cg26685941</td>\n",
       "      <td>cg06639320</td>\n",
       "      <td>cg04875128</td>\n",
       "      <td>cg24079702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cg04295144</td>\n",
       "      <td>cg04875128</td>\n",
       "      <td>cg06639320</td>\n",
       "      <td>cg10501210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cg15951188</td>\n",
       "      <td>cg19283806</td>\n",
       "      <td>cg24724428</td>\n",
       "      <td>cg00292135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cg22242842</td>\n",
       "      <td>cg23500537</td>\n",
       "      <td>cg15341124</td>\n",
       "      <td>cg06833647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cg07082267</td>\n",
       "      <td>cg25478614</td>\n",
       "      <td>cg21572722</td>\n",
       "      <td>cg09118555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cg01282174</td>\n",
       "      <td>cg17110586</td>\n",
       "      <td>cg05404236</td>\n",
       "      <td>cg19890168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cg05207048</td>\n",
       "      <td>cg24724428</td>\n",
       "      <td>cg13033938</td>\n",
       "      <td>cg03064228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cg00787180</td>\n",
       "      <td>cg19392831</td>\n",
       "      <td>cg11705975</td>\n",
       "      <td>cg12287055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cg14956327</td>\n",
       "      <td>cg06335143</td>\n",
       "      <td>cg26685941</td>\n",
       "      <td>cg02405619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cg04503319</td>\n",
       "      <td>cg03725309</td>\n",
       "      <td>cg14361627</td>\n",
       "      <td>cg06352932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cg03054277</td>\n",
       "      <td>cg07547549</td>\n",
       "      <td>cg12934382</td>\n",
       "      <td>cg05445137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cg07785717</td>\n",
       "      <td>cg25410668</td>\n",
       "      <td>cg25410668</td>\n",
       "      <td>cg04875128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cg07739179</td>\n",
       "      <td>cg26685941</td>\n",
       "      <td>cg07553761</td>\n",
       "      <td>cg07117364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cg08957484</td>\n",
       "      <td>cg13848598</td>\n",
       "      <td>cg14556683</td>\n",
       "      <td>cg03871162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cg04453050</td>\n",
       "      <td>cg08468401</td>\n",
       "      <td>cg07547549</td>\n",
       "      <td>cg15491967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cg16290275</td>\n",
       "      <td>cg07945335</td>\n",
       "      <td>cg11071401</td>\n",
       "      <td>cg17763192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cg00664406</td>\n",
       "      <td>cg05017994</td>\n",
       "      <td>cg23798387</td>\n",
       "      <td>cg11480068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cg02046143</td>\n",
       "      <td>cg01877778</td>\n",
       "      <td>cg11084334</td>\n",
       "      <td>cg01717010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cg06419432</td>\n",
       "      <td>cg06970472</td>\n",
       "      <td>cg10501210</td>\n",
       "      <td>cg24724428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cg18055623</td>\n",
       "      <td>cg15121420</td>\n",
       "      <td>cg00664406</td>\n",
       "      <td>cg08930944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cg22454769</td>\n",
       "      <td>cg17287155</td>\n",
       "      <td>cg13327545</td>\n",
       "      <td>cg13649060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cg22016779</td>\n",
       "      <td>cg09988805</td>\n",
       "      <td>cg24125828</td>\n",
       "      <td>ch.2.109048761R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cg18887458</td>\n",
       "      <td>cg17820878</td>\n",
       "      <td>cg00094518</td>\n",
       "      <td>cg06674392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cg21878650</td>\n",
       "      <td>cg18064714</td>\n",
       "      <td>cg05213896</td>\n",
       "      <td>cg17256729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cg19421125</td>\n",
       "      <td>cg01974375</td>\n",
       "      <td>cg17953764</td>\n",
       "      <td>cg00283771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cg14010720</td>\n",
       "      <td>cg01973676</td>\n",
       "      <td>cg13848598</td>\n",
       "      <td>cg04016765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cg12419863</td>\n",
       "      <td>cg12534424</td>\n",
       "      <td>cg22016779</td>\n",
       "      <td>cg25844366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0-34       60-78       34-60              78+\n",
       "0   cg16867657  cg16867657  cg16867657       cg14571574\n",
       "1   cg05412028  cg22454769  cg22454769       cg24273318\n",
       "2   cg19283806  cg21572722  cg19283806       cg01763090\n",
       "3   cg26685941  cg06639320  cg04875128       cg24079702\n",
       "4   cg04295144  cg04875128  cg06639320       cg10501210\n",
       "5   cg15951188  cg19283806  cg24724428       cg00292135\n",
       "6   cg22242842  cg23500537  cg15341124       cg06833647\n",
       "7   cg07082267  cg25478614  cg21572722       cg09118555\n",
       "8   cg01282174  cg17110586  cg05404236       cg19890168\n",
       "9   cg05207048  cg24724428  cg13033938       cg03064228\n",
       "10  cg00787180  cg19392831  cg11705975       cg12287055\n",
       "11  cg14956327  cg06335143  cg26685941       cg02405619\n",
       "12  cg04503319  cg03725309  cg14361627       cg06352932\n",
       "13  cg03054277  cg07547549  cg12934382       cg05445137\n",
       "14  cg07785717  cg25410668  cg25410668       cg04875128\n",
       "15  cg07739179  cg26685941  cg07553761       cg07117364\n",
       "16  cg08957484  cg13848598  cg14556683       cg03871162\n",
       "17  cg04453050  cg08468401  cg07547549       cg15491967\n",
       "18  cg16290275  cg07945335  cg11071401       cg17763192\n",
       "19  cg00664406  cg05017994  cg23798387       cg11480068\n",
       "20  cg02046143  cg01877778  cg11084334       cg01717010\n",
       "21  cg06419432  cg06970472  cg10501210       cg24724428\n",
       "22  cg18055623  cg15121420  cg00664406       cg08930944\n",
       "23  cg22454769  cg17287155  cg13327545       cg13649060\n",
       "24  cg22016779  cg09988805  cg24125828  ch.2.109048761R\n",
       "25  cg18887458  cg17820878  cg00094518       cg06674392\n",
       "26  cg21878650  cg18064714  cg05213896       cg17256729\n",
       "27  cg19421125  cg01974375  cg17953764       cg00283771\n",
       "28  cg14010720  cg01973676  cg13848598       cg04016765\n",
       "29  cg12419863  cg12534424  cg22016779       cg25844366"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_30_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4c6460-715a-46b4-a7b2-c11c524faee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = fold_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2701f688-3504-46a6-bba5-aa1d24f6f7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.8480\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0-34       0.97      0.96      0.97       759\n",
      "       34-60       0.82      0.93      0.87      1075\n",
      "       60-78       0.71      0.60      0.65       480\n",
      "         78+       0.78      0.10      0.18        68\n",
      "\n",
      "    accuracy                           0.85      2382\n",
      "   macro avg       0.82      0.65      0.67      2382\n",
      "weighted avg       0.84      0.85      0.84      2382\n",
      "\n",
      "     Actual Age Group Predicted Age Group\n",
      "0                0-34                0-34\n",
      "1                0-34                0-34\n",
      "2                0-34                0-34\n",
      "3                0-34                0-34\n",
      "4                0-34                0-34\n",
      "...               ...                 ...\n",
      "2377              78+               60-78\n",
      "2378              78+               60-78\n",
      "2379              78+               60-78\n",
      "2380              78+               60-78\n",
      "2381              78+               60-78\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.drop(['age', 'age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=str))  # Keeping as string since we have non-numeric age groups\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d72b12-655f-45e9-b14a-8f502a33814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3078, 30)\n",
      "Age Group: 0-34, MSE: 3.4423559389911307, Model saved as: models\\EBM_model_age_group_0-34.joblib\n",
      "(4350, 30)\n",
      "Age Group: 34-60, MSE: 9.877452665791957, Model saved as: models\\EBM_model_age_group_34-60.joblib\n",
      "(1881, 30)\n",
      "Age Group: 60-78, MSE: 9.420236419424015, Model saved as: models\\EBM_model_age_group_60-78.joblib\n",
      "(219, 30)\n",
      "Age Group: 78+, MSE: 6.936531124471692, Model saved as: models\\EBM_model_age_group_78+.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = top_30_features_df\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "# Define function to map ages to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Apply the function to create age groups\n",
    "train_df['age_group'] = train_df['age'].apply(age_to_group)\n",
    "test_df['age_group'] = test_df['age'].apply(age_to_group)\n",
    "\n",
    "unique_age_groups = train_df['age_group'].unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[train_df['age_group'] == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[age_group]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data['age']\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5, greedy_ratio=0, inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}, MSE: {mse}, Model saved as: {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cd465-72c5-4394-925a-569466f86277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae97aad-ff4e-4d05-8c81-af413315eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on Test Data: 6.5550\n",
      "Mean Absolute Error (MAE) on Test Data: 4.1045\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.columns.drop(['age', 'age_group'])\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0-34', '34-60', '60-78', '78+']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Prepare Train using top 30 features\n",
    "def prepare_train_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_test, y_test = prepare_train_data(test_data, top_30_features)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109215c-8a78-431c-9759-1457c031e083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae06147-6496-452f-a57e-27b83b27802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = fold_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e898acd-bf2e-4f05-975a-1c75e50e2423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.8774\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0-34       0.96      0.96      0.96       801\n",
      "       34-60       0.85      0.93      0.89      1053\n",
      "       60-78       0.79      0.69      0.74       474\n",
      "         78+       0.90      0.17      0.28        54\n",
      "\n",
      "    accuracy                           0.88      2382\n",
      "   macro avg       0.88      0.69      0.72      2382\n",
      "weighted avg       0.88      0.88      0.87      2382\n",
      "\n",
      "     Actual Age Group Predicted Age Group\n",
      "0                0-34                0-34\n",
      "1                0-34                0-34\n",
      "2                0-34                0-34\n",
      "3                0-34                0-34\n",
      "4                0-34                0-34\n",
      "...               ...                 ...\n",
      "2377              78+               60-78\n",
      "2378              78+               60-78\n",
      "2379              78+               60-78\n",
      "2380              78+               60-78\n",
      "2381              78+               60-78\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.drop(['age', 'age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=str))  # Keeping as string since we have non-numeric age groups\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ab08e2-c4b3-468d-9fc5-90e78594b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3036, 30)\n",
      "Age Group: 0-34, MSE: 2.780860543937726, Model saved as: models\\EBM_model_age_group_0-34.joblib\n",
      "(4372, 30)\n",
      "Age Group: 34-60, MSE: 9.642502205851583, Model saved as: models\\EBM_model_age_group_34-60.joblib\n",
      "(1887, 30)\n",
      "Age Group: 60-78, MSE: 9.839534888815793, Model saved as: models\\EBM_model_age_group_60-78.joblib\n",
      "(233, 30)\n",
      "Age Group: 78+, MSE: 4.3168119568945205, Model saved as: models\\EBM_model_age_group_78+.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = top_30_features_df\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "# Define function to map ages to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Apply the function to create age groups\n",
    "train_df['age_group'] = train_df['age'].apply(age_to_group)\n",
    "test_df['age_group'] = test_df['age'].apply(age_to_group)\n",
    "\n",
    "unique_age_groups = train_df['age_group'].unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[train_df['age_group'] == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[age_group]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data['age']\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5, greedy_ratio=0, inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}, MSE: {mse}, Model saved as: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b278473-5884-408a-9aa9-95a844d5e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on Test Data: 6.3510\n",
      "Mean Absolute Error (MAE) on Test Data: 3.8388\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.columns.drop(['age', 'age_group'])\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0-34', '34-60', '60-78', '78+']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Prepare Train using top 30 features\n",
    "def prepare_train_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_test, y_test = prepare_train_data(test_data, top_30_features)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfec5d6-7d1c-4379-9bac-d381f7a1b063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f038835-3ff6-4326-a4ef-9e267a209d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = fold_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a234569-3269-4142-8596-e456bb2bacf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.8606\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0-34       0.96      0.96      0.96       769\n",
      "       34-60       0.84      0.92      0.88      1088\n",
      "       60-78       0.73      0.64      0.68       464\n",
      "         78+       0.73      0.18      0.29        61\n",
      "\n",
      "    accuracy                           0.86      2382\n",
      "   macro avg       0.82      0.68      0.70      2382\n",
      "weighted avg       0.86      0.86      0.85      2382\n",
      "\n",
      "     Actual Age Group Predicted Age Group\n",
      "0                0-34                0-34\n",
      "1                0-34                0-34\n",
      "2                0-34                0-34\n",
      "3                0-34                0-34\n",
      "4                0-34                0-34\n",
      "...               ...                 ...\n",
      "2377              78+               60-78\n",
      "2378              78+               60-78\n",
      "2379              78+                 78+\n",
      "2380              78+                 78+\n",
      "2381              78+               60-78\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.drop(['age', 'age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=str))  # Keeping as string since we have non-numeric age groups\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876ba6c5-dca7-4c3e-b6f3-fe9e82ad6ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3068, 30)\n",
      "Age Group: 0-34, MSE: 3.0017002861063364, Model saved as: models\\EBM_model_age_group_0-34.joblib\n",
      "(4337, 30)\n",
      "Age Group: 34-60, MSE: 10.10635056197224, Model saved as: models\\EBM_model_age_group_34-60.joblib\n",
      "(1897, 30)\n",
      "Age Group: 60-78, MSE: 9.187446556824815, Model saved as: models\\EBM_model_age_group_60-78.joblib\n",
      "(226, 30)\n",
      "Age Group: 78+, MSE: 6.190863325320099, Model saved as: models\\EBM_model_age_group_78+.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = top_30_features_df\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "# Define function to map ages to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Apply the function to create age groups\n",
    "train_df['age_group'] = train_df['age'].apply(age_to_group)\n",
    "test_df['age_group'] = test_df['age'].apply(age_to_group)\n",
    "\n",
    "unique_age_groups = train_df['age_group'].unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[train_df['age_group'] == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[age_group]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data['age']\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5, greedy_ratio=0, inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}, MSE: {mse}, Model saved as: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8566379c-4f66-4bea-9b9d-21d766137935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on Test Data: 6.0194\n",
      "Mean Absolute Error (MAE) on Test Data: 3.8643\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.columns.drop(['age', 'age_group'])\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0-34', '34-60', '60-78', '78+']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Prepare Train using top 30 features\n",
    "def prepare_train_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_test, y_test = prepare_train_data(test_data, top_30_features)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794765d-6ccb-422c-8e48-16a167d05f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c4c9e4-77c9-4ba2-aeff-452a0a18393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = fold_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b45143f-3ba0-4afb-94dd-6f580ddbd35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.8686\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0-34       0.97      0.96      0.96       743\n",
      "       34-60       0.84      0.94      0.89      1112\n",
      "       60-78       0.78      0.64      0.70       471\n",
      "         78+       0.86      0.11      0.19        56\n",
      "\n",
      "    accuracy                           0.87      2382\n",
      "   macro avg       0.86      0.66      0.69      2382\n",
      "weighted avg       0.87      0.87      0.86      2382\n",
      "\n",
      "     Actual Age Group Predicted Age Group\n",
      "0                0-34                0-34\n",
      "1                0-34                0-34\n",
      "2                0-34                0-34\n",
      "3                0-34                0-34\n",
      "4                0-34                0-34\n",
      "...               ...                 ...\n",
      "2377              78+               60-78\n",
      "2378              78+               60-78\n",
      "2379              78+               34-60\n",
      "2380              78+               60-78\n",
      "2381              78+               34-60\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.drop(['age', 'age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=str))  # Keeping as string since we have non-numeric age groups\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e796b242-ea79-45d4-9f85-b12466bd05fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3094, 30)\n",
      "Age Group: 0-34, MSE: 3.132372703582305, Model saved as: models\\EBM_model_age_group_0-34.joblib\n",
      "(4313, 30)\n",
      "Age Group: 34-60, MSE: 10.014699841672208, Model saved as: models\\EBM_model_age_group_34-60.joblib\n",
      "(1890, 30)\n",
      "Age Group: 60-78, MSE: 9.288893702381664, Model saved as: models\\EBM_model_age_group_60-78.joblib\n",
      "(231, 30)\n",
      "Age Group: 78+, MSE: 3.885761105388882, Model saved as: models\\EBM_model_age_group_78+.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = top_30_features_df\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "# Define function to map ages to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Apply the function to create age groups\n",
    "train_df['age_group'] = train_df['age'].apply(age_to_group)\n",
    "test_df['age_group'] = test_df['age'].apply(age_to_group)\n",
    "\n",
    "unique_age_groups = train_df['age_group'].unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[train_df['age_group'] == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[age_group]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data['age']\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5, greedy_ratio=0, inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}, MSE: {mse}, Model saved as: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d926af4-7440-4193-b72e-35283604b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on Test Data: 6.3435\n",
      "Mean Absolute Error (MAE) on Test Data: 3.9399\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.columns.drop(['age', 'age_group'])\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0-34', '34-60', '60-78', '78+']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Prepare Train using top 30 features\n",
    "def prepare_train_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_test, y_test = prepare_train_data(test_data, top_30_features)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf2c9a-cec4-4a0d-8616-2c81948df19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5273db-05b4-406a-befc-897adaf64acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = fold_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ed2995-e256-43b9-979b-706684f28665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.8728\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0-34       0.96      0.96      0.96       765\n",
      "       34-60       0.84      0.94      0.89      1097\n",
      "       60-78       0.80      0.66      0.72       472\n",
      "         78+       0.75      0.19      0.30        48\n",
      "\n",
      "    accuracy                           0.87      2382\n",
      "   macro avg       0.84      0.68      0.72      2382\n",
      "weighted avg       0.87      0.87      0.87      2382\n",
      "\n",
      "     Actual Age Group Predicted Age Group\n",
      "0                0-34                0-34\n",
      "1                0-34                0-34\n",
      "2                0-34                0-34\n",
      "3                0-34                0-34\n",
      "4                0-34                0-34\n",
      "...               ...                 ...\n",
      "2377              78+               60-78\n",
      "2378              78+               60-78\n",
      "2379              78+               60-78\n",
      "2380              78+               34-60\n",
      "2381              78+               34-60\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.drop(['age', 'age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=str))  # Keeping as string since we have non-numeric age groups\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef424397-f88b-40ea-b348-4099642e7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 30)\n",
      "Age Group: 0-34, MSE: 3.107167509037312, Model saved as: models\\EBM_model_age_group_0-34.joblib\n",
      "(4328, 30)\n",
      "Age Group: 34-60, MSE: 9.923692672369786, Model saved as: models\\EBM_model_age_group_34-60.joblib\n",
      "(1889, 30)\n",
      "Age Group: 60-78, MSE: 9.81673643552513, Model saved as: models\\EBM_model_age_group_60-78.joblib\n",
      "(239, 30)\n",
      "Age Group: 78+, MSE: 5.729575510071648, Model saved as: models\\EBM_model_age_group_78+.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = top_30_features_df\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "# Define function to map ages to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Apply the function to create age groups\n",
    "train_df['age_group'] = train_df['age'].apply(age_to_group)\n",
    "test_df['age_group'] = test_df['age'].apply(age_to_group)\n",
    "\n",
    "unique_age_groups = train_df['age_group'].unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[train_df['age_group'] == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[age_group]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data['age']\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5, greedy_ratio=0, inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}, MSE: {mse}, Model saved as: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e20561-c24e-43a3-ae1e-b02b661bc11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on Test Data: 6.0540\n",
      "Mean Absolute Error (MAE) on Test Data: 3.8422\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define function to convert age to the new age groups\n",
    "def age_to_group(age):\n",
    "    if age < 34:\n",
    "        return '0-34'\n",
    "    elif age < 60:\n",
    "        return '34-60'\n",
    "    elif age < 78:\n",
    "        return '60-78'\n",
    "    else:\n",
    "        return '78+'\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.columns.drop(['age', 'age_group'])\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0-34', '34-60', '60-78', '78+']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Prepare Train using top 30 features\n",
    "def prepare_train_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_test, y_test = prepare_train_data(test_data, top_30_features)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c4b78-8a65-46f6-9bce-5e50e6287619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4368a8a-c679-40e3-ab92-1e1314069fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6122d-aef9-4c0f-bab8-eb512c09a7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
