{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0145c2d-2cc8-46df-98b4-440885290569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "\n",
    "# Ensure the age group keys are strings\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "def split_data_by_age_cv(df, age_column='age', n_splits=5, random_state=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    age_groups = df.groupby(df[age_column] // 10 * 10)\n",
    "    \n",
    "    fold_data = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_list = []\n",
    "        test_list = []\n",
    "        \n",
    "        for _, group in age_groups:\n",
    "            group_train_index = [idx for idx in train_index if idx in group.index]\n",
    "            group_test_index = [idx for idx in test_index if idx in group.index]\n",
    "            \n",
    "            train = group.loc[group_train_index]\n",
    "            test = group.loc[group_test_index]\n",
    "            \n",
    "            train_list.append(train)\n",
    "            test_list.append(test)\n",
    "        \n",
    "        train_df = pd.concat(train_list, ignore_index=True)\n",
    "        test_df = pd.concat(test_list, ignore_index=True)\n",
    "        \n",
    "        fold_data.append((train_df, test_df))\n",
    "    \n",
    "    return fold_data\n",
    "\n",
    "# Example usage\n",
    "imputed_data = pd.read_csv('imputed_data.csv',index_col =0)  # Replace with your actual data\n",
    "fold_data = split_data_by_age_cv(imputed_data)\n",
    "\n",
    "# Plotting the age distribution for the first fold's train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df249c78-7d1a-4c91-a01c-0eb01c86011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = fold_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b2e524-b749-4c50-b301-989e6510a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.6520\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       144\n",
      "          10       0.95      0.98      0.96       413\n",
      "          20       0.70      0.70      0.70       151\n",
      "          30       0.57      0.50      0.53       226\n",
      "          40       0.55      0.68      0.61       440\n",
      "          50       0.53      0.57      0.55       488\n",
      "          60       0.53      0.48      0.51       336\n",
      "          70       0.51      0.28      0.36       148\n",
      "          80       0.80      0.13      0.23        30\n",
      "          90       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.65      2382\n",
      "   macro avg       0.66      0.55      0.57      2382\n",
      "weighted avg       0.65      0.65      0.64      2382\n",
      "\n",
      "      Actual Age Group  Predicted Age Group\n",
      "0                    0                    0\n",
      "1                    0                    0\n",
      "2                    0                    0\n",
      "3                    0                    0\n",
      "4                    0                    0\n",
      "...                ...                  ...\n",
      "2377                90                   90\n",
      "2378                90                   70\n",
      "2379                90                   70\n",
      "2380                90                   70\n",
      "2381                90                   70\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return (age // 10) * 10\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age'] // 10 * 10\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features =  group_data.drop(['age','age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=np.int32))\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf81c99-b56c-49ae-b4fb-b7c3e2fc36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 30)\n",
      "Age Group: 0.0-9.0, MSE: 0.06115656607487444, Model saved as: models\\EBM_model_age_group_0.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853187999248/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853187999248/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853179234448/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853179234448/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1704, 30)\n",
      "Age Group: 10.0-19.0, MSE: 0.13035405091561272, Model saved as: models\\EBM_model_age_group_10.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853176424528/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853176424528/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853154787024/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853154787024/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574, 30)\n",
      "Age Group: 20.0-29.0, MSE: 2.8261296512623084, Model saved as: models\\EBM_model_age_group_20.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853179731280/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853179731280/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853176548496/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853176548496/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877, 30)\n",
      "Age Group: 30.0-39.0, MSE: 3.089915243482211, Model saved as: models\\EBM_model_age_group_30.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853189358160/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853189358160/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853205832912/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853205832912/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1741, 30)\n",
      "Age Group: 40.0-49.0, MSE: 4.161589466250099, Model saved as: models\\EBM_model_age_group_40.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853209299024/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853209299024/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853213248080/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853213248080/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1924, 30)\n",
      "Age Group: 50.0-59.0, MSE: 5.3932709817306, Model saved as: models\\EBM_model_age_group_50.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853213015888/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853213015888/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853213140176/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853213140176/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1392, 30)\n",
      "Age Group: 60.0-69.0, MSE: 4.7428774316270275, Model saved as: models\\EBM_model_age_group_60.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853213256848/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853213256848/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853217233424/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853217233424/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568, 30)\n",
      "Age Group: 70.0-79.0, MSE: 4.211032339370485, Model saved as: models\\EBM_model_age_group_70.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853218345744/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853218345744/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853217586128/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853217586128/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 30)\n",
      "Age Group: 80.0-89.0, MSE: 1.5930211403185164, Model saved as: models\\EBM_model_age_group_80.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853675294352/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853675294352/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1855080181456/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1855080181456/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 30)\n",
      "Age Group: 90.0-99.0, MSE: 0.27286454406202937, Model saved as: models\\EBM_model_age_group_90.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1855080320592/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1855080320592/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1858482589584/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1858482589584/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 30)\n",
      "Age Group: 100.0-109.0, MSE: 1167.6968980975703, Model saved as: models\\EBM_model_age_group_100.0.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1855080890768/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1855080890768/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1853675489936/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1853675489936/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age Group 0.0  Age Group 10.0  Age Group 20.0  Age Group 30.0  \\\n",
      "0        0.094239        0.025142        0.190447        0.423137   \n",
      "1        0.077629        0.032502        0.143500        0.158028   \n",
      "2        0.087692        0.007632        0.060307        0.142383   \n",
      "3        0.085297        0.005184        0.117107        0.176928   \n",
      "4        0.081918        0.020781        0.074821        0.029513   \n",
      "5        0.122286        0.019343        0.109038        0.114403   \n",
      "6        0.074189        0.009641        0.220315        0.184398   \n",
      "7        0.099230        0.019168        0.068759        0.035670   \n",
      "8        0.086888        0.022453        0.609557        0.184991   \n",
      "9        0.077531        0.014310        0.071893        0.092908   \n",
      "10       0.082840        0.019401        0.071020        0.073473   \n",
      "11       0.098920        0.017130        0.034790        0.050810   \n",
      "12       0.060742        0.025398        0.047223        0.050858   \n",
      "13       0.071635        0.021739        0.056981        0.071114   \n",
      "14       0.089437        0.016998        0.071919        0.068820   \n",
      "15       0.080260        0.014069        0.053044        0.064193   \n",
      "16       0.058829        0.006501        0.162115        0.064676   \n",
      "17       0.049554        0.003479        0.032395        0.056560   \n",
      "18       0.066099        0.028267        0.060717        0.031352   \n",
      "19       0.073296        0.005479        0.118411        0.113448   \n",
      "20       0.039978        0.008685        0.113433        0.042064   \n",
      "21       0.035696        0.006338        0.104381        0.055553   \n",
      "22       0.069439        0.014535        0.036222        0.080931   \n",
      "23       0.069785        0.013492        0.218026        0.065863   \n",
      "24       0.055753        0.005235        0.128403        0.032929   \n",
      "25       0.039251        0.004085        0.058953        0.048727   \n",
      "26       0.031399        0.012503        0.156466        0.043142   \n",
      "27       0.039325        0.019866        0.052947        0.115960   \n",
      "28       0.087006        0.003684        0.091530        0.076390   \n",
      "29       0.054986        0.006032        0.046588        0.053185   \n",
      "\n",
      "    Age Group 40.0  Age Group 50.0  Age Group 60.0  Age Group 70.0  \\\n",
      "0         0.333237        0.327271        0.230681        0.056739   \n",
      "1         0.199565        0.194883        0.226366        0.195659   \n",
      "2         0.104037        0.113457        0.094752        0.189281   \n",
      "3         0.198905        0.174796        0.102264        0.086317   \n",
      "4         0.174442        0.058287        0.217348        0.085507   \n",
      "5         0.107905        0.100544        0.131095        0.088613   \n",
      "6         0.082036        0.058022        0.157773        0.113220   \n",
      "7         0.170771        0.243030        0.054309        0.060492   \n",
      "8         0.089317        0.052745        0.108106        0.101469   \n",
      "9         0.152552        0.029502        0.080686        0.075368   \n",
      "10        0.134908        0.061613        0.200575        0.175850   \n",
      "11        0.154720        0.169439        0.026357        0.027090   \n",
      "12        0.220955        0.040545        0.078325        0.036970   \n",
      "13        0.385247        0.143378        0.067052        0.091065   \n",
      "14        0.172632        0.019786        0.042591        0.136498   \n",
      "15        0.071230        0.050728        0.047492        0.074324   \n",
      "16        0.075555        0.071093        0.065569        0.073912   \n",
      "17        0.059069        0.046889        0.040429        0.208588   \n",
      "18        0.075573        0.028425        0.049715        0.021757   \n",
      "19        0.059418        0.045501        0.047720        0.045397   \n",
      "20        0.148374        0.028026        0.064843        0.052662   \n",
      "21        0.047351        0.022264        0.058868        0.044225   \n",
      "22        0.072388        0.028313        0.063613        0.113717   \n",
      "23        0.084436        0.034769        0.127498        0.053031   \n",
      "24        0.125749        0.029136        0.064044        0.045880   \n",
      "25        0.038044        0.028833        0.057305        0.050479   \n",
      "26        0.044810        0.031598        0.067569        0.055842   \n",
      "27        0.072098        0.045011        0.069484        0.026901   \n",
      "28        0.019898        0.053933        0.051007        0.056095   \n",
      "29        0.044741        0.060043        0.056388        0.090092   \n",
      "\n",
      "    Age Group 80.0  Age Group 90.0  Age Group 100.0  \n",
      "0         0.189233        0.261403         0.297540  \n",
      "1         0.070313        0.100161         0.295195  \n",
      "2         0.163476        0.057221         0.292869  \n",
      "3         0.033226        0.059816         0.290562  \n",
      "4         0.106094        0.069533         0.288273  \n",
      "5         0.065637        0.124201         0.286003  \n",
      "6         0.100621        0.165769         0.283751  \n",
      "7         0.076701        0.086122         0.281517  \n",
      "8         0.083777        0.028749         0.279302  \n",
      "9         0.068262        0.092727         0.277104  \n",
      "10        0.079379        0.071095         0.274924  \n",
      "11        0.073843        0.144519         0.272762  \n",
      "12        0.112091        0.043638         0.270617  \n",
      "13        0.156859        0.211336         0.268489  \n",
      "14        0.061977        0.105158         0.266379  \n",
      "15        0.049206        0.062684         0.264285  \n",
      "16        0.094663        0.072196         0.262209  \n",
      "17        0.110554        0.197825         0.260149  \n",
      "18        0.124519        0.061639         0.258106  \n",
      "19        0.058084        0.029302         0.256079  \n",
      "20        0.051386        0.165529         0.254068  \n",
      "21        0.045411        0.044632         0.252074  \n",
      "22        0.043961        0.132557         0.250096  \n",
      "23        0.096762        0.037319         0.248134  \n",
      "24        0.094833        0.046654         0.246188  \n",
      "25        0.041861        0.041614         0.244257  \n",
      "26        0.069011        0.101818         0.242342  \n",
      "27        0.109291        0.126639         0.240442  \n",
      "28        0.069639        0.043721         0.238557  \n",
      "29        0.054810        0.054026         0.368236  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from interpret import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Ensure the explanation images save directory exists\n",
    "explanation_save_dir = 'explanations'\n",
    "os.makedirs(explanation_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "age_column = 'age'\n",
    "age_groups = train_df[age_column] // 10 * 10\n",
    "unique_age_groups = age_groups.unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[age_groups == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[str(age_group)]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data[age_column]\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5, greedy_ratio=0, inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}-{age_group+9}, MSE: {mse}, Model saved as: {model_filename}\")\n",
    "\n",
    "    # Save feature importances\n",
    "    feature_importance = model.explain_global().data()\n",
    "    feature_importance_df = pd.DataFrame(feature_importance['scores'][:30], columns=[f'Age Group {age_group}'])\n",
    "    feature_importance_matrix = pd.concat([feature_importance_matrix, feature_importance_df], axis=1)\n",
    "\n",
    "    # Save global explanation\n",
    "    global_explanation = model.explain_global()\n",
    "    show(global_explanation)\n",
    "    global_explanation_filename = os.path.join(explanation_save_dir, f'global_explanation_age_group_{age_group}.png')\n",
    "    plt.savefig(global_explanation_filename)\n",
    "    plt.close()\n",
    "\n",
    "    # Save local explanation for a sample\n",
    "    local_explanation = model.explain_local(X_train.iloc[:5], y_train.iloc[:5])\n",
    "    show(local_explanation)\n",
    "    local_explanation_filename = os.path.join(explanation_save_dir, f'local_explanation_age_group_{age_group}.png')\n",
    "    plt.savefig(local_explanation_filename)\n",
    "    plt.close()\n",
    "\n",
    "# Print the feature importance matrix\n",
    "print(feature_importance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66f266-2343-4e72-89fc-2030ca6243e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6eec21-9d95-4698-9c3c-6ca947408e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa411e7d-fa17-440f-b61d-401084c759c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 30)\n",
      "Age Group: 0.0-9.0, MSE: 0.06115656607487444, Model saved as: models\\EBM_model_age_group_0.0.joblib\n",
      "(1704, 30)\n",
      "Age Group: 10.0-19.0, MSE: 0.13035405091561272, Model saved as: models\\EBM_model_age_group_10.0.joblib\n",
      "(574, 30)\n",
      "Age Group: 20.0-29.0, MSE: 2.8261296512623084, Model saved as: models\\EBM_model_age_group_20.0.joblib\n",
      "(877, 30)\n",
      "Age Group: 30.0-39.0, MSE: 3.089915243482211, Model saved as: models\\EBM_model_age_group_30.0.joblib\n",
      "(1741, 30)\n",
      "Age Group: 40.0-49.0, MSE: 4.161589466250099, Model saved as: models\\EBM_model_age_group_40.0.joblib\n",
      "(1924, 30)\n",
      "Age Group: 50.0-59.0, MSE: 5.3932709817306, Model saved as: models\\EBM_model_age_group_50.0.joblib\n",
      "(1392, 30)\n",
      "Age Group: 60.0-69.0, MSE: 4.7428774316270275, Model saved as: models\\EBM_model_age_group_60.0.joblib\n",
      "(568, 30)\n",
      "Age Group: 70.0-79.0, MSE: 4.211032339370485, Model saved as: models\\EBM_model_age_group_70.0.joblib\n",
      "(139, 30)\n",
      "Age Group: 80.0-89.0, MSE: 1.5930211403185164, Model saved as: models\\EBM_model_age_group_80.0.joblib\n",
      "(26, 30)\n",
      "Age Group: 90.0-99.0, MSE: 0.27286454406202937, Model saved as: models\\EBM_model_age_group_90.0.joblib\n",
      "(3, 30)\n",
      "Age Group: 100.0-109.0, MSE: 1167.6968980975703, Model saved as: models\\EBM_model_age_group_100.0.joblib\n",
      "    Age Group 0.0  Age Group 10.0  Age Group 20.0  Age Group 30.0  \\\n",
      "0        0.094239        0.025142        0.190447        0.423137   \n",
      "1        0.077629        0.032502        0.143500        0.158028   \n",
      "2        0.087692        0.007632        0.060307        0.142383   \n",
      "3        0.085297        0.005184        0.117107        0.176928   \n",
      "4        0.081918        0.020781        0.074821        0.029513   \n",
      "5        0.122286        0.019343        0.109038        0.114403   \n",
      "6        0.074189        0.009641        0.220315        0.184398   \n",
      "7        0.099230        0.019168        0.068759        0.035670   \n",
      "8        0.086888        0.022453        0.609557        0.184991   \n",
      "9        0.077531        0.014310        0.071893        0.092908   \n",
      "10       0.082840        0.019401        0.071020        0.073473   \n",
      "11       0.098920        0.017130        0.034790        0.050810   \n",
      "12       0.060742        0.025398        0.047223        0.050858   \n",
      "13       0.071635        0.021739        0.056981        0.071114   \n",
      "14       0.089437        0.016998        0.071919        0.068820   \n",
      "15       0.080260        0.014069        0.053044        0.064193   \n",
      "16       0.058829        0.006501        0.162115        0.064676   \n",
      "17       0.049554        0.003479        0.032395        0.056560   \n",
      "18       0.066099        0.028267        0.060717        0.031352   \n",
      "19       0.073296        0.005479        0.118411        0.113448   \n",
      "20       0.039978        0.008685        0.113433        0.042064   \n",
      "21       0.035696        0.006338        0.104381        0.055553   \n",
      "22       0.069439        0.014535        0.036222        0.080931   \n",
      "23       0.069785        0.013492        0.218026        0.065863   \n",
      "24       0.055753        0.005235        0.128403        0.032929   \n",
      "25       0.039251        0.004085        0.058953        0.048727   \n",
      "26       0.031399        0.012503        0.156466        0.043142   \n",
      "27       0.039325        0.019866        0.052947        0.115960   \n",
      "28       0.087006        0.003684        0.091530        0.076390   \n",
      "29       0.054986        0.006032        0.046588        0.053185   \n",
      "\n",
      "    Age Group 40.0  Age Group 50.0  Age Group 60.0  Age Group 70.0  \\\n",
      "0         0.333237        0.327271        0.230681        0.056739   \n",
      "1         0.199565        0.194883        0.226366        0.195659   \n",
      "2         0.104037        0.113457        0.094752        0.189281   \n",
      "3         0.198905        0.174796        0.102264        0.086317   \n",
      "4         0.174442        0.058287        0.217348        0.085507   \n",
      "5         0.107905        0.100544        0.131095        0.088613   \n",
      "6         0.082036        0.058022        0.157773        0.113220   \n",
      "7         0.170771        0.243030        0.054309        0.060492   \n",
      "8         0.089317        0.052745        0.108106        0.101469   \n",
      "9         0.152552        0.029502        0.080686        0.075368   \n",
      "10        0.134908        0.061613        0.200575        0.175850   \n",
      "11        0.154720        0.169439        0.026357        0.027090   \n",
      "12        0.220955        0.040545        0.078325        0.036970   \n",
      "13        0.385247        0.143378        0.067052        0.091065   \n",
      "14        0.172632        0.019786        0.042591        0.136498   \n",
      "15        0.071230        0.050728        0.047492        0.074324   \n",
      "16        0.075555        0.071093        0.065569        0.073912   \n",
      "17        0.059069        0.046889        0.040429        0.208588   \n",
      "18        0.075573        0.028425        0.049715        0.021757   \n",
      "19        0.059418        0.045501        0.047720        0.045397   \n",
      "20        0.148374        0.028026        0.064843        0.052662   \n",
      "21        0.047351        0.022264        0.058868        0.044225   \n",
      "22        0.072388        0.028313        0.063613        0.113717   \n",
      "23        0.084436        0.034769        0.127498        0.053031   \n",
      "24        0.125749        0.029136        0.064044        0.045880   \n",
      "25        0.038044        0.028833        0.057305        0.050479   \n",
      "26        0.044810        0.031598        0.067569        0.055842   \n",
      "27        0.072098        0.045011        0.069484        0.026901   \n",
      "28        0.019898        0.053933        0.051007        0.056095   \n",
      "29        0.044741        0.060043        0.056388        0.090092   \n",
      "\n",
      "    Age Group 80.0  Age Group 90.0  Age Group 100.0  \n",
      "0         0.189233        0.261403         0.297540  \n",
      "1         0.070313        0.100161         0.295195  \n",
      "2         0.163476        0.057221         0.292869  \n",
      "3         0.033226        0.059816         0.290562  \n",
      "4         0.106094        0.069533         0.288273  \n",
      "5         0.065637        0.124201         0.286003  \n",
      "6         0.100621        0.165769         0.283751  \n",
      "7         0.076701        0.086122         0.281517  \n",
      "8         0.083777        0.028749         0.279302  \n",
      "9         0.068262        0.092727         0.277104  \n",
      "10        0.079379        0.071095         0.274924  \n",
      "11        0.073843        0.144519         0.272762  \n",
      "12        0.112091        0.043638         0.270617  \n",
      "13        0.156859        0.211336         0.268489  \n",
      "14        0.061977        0.105158         0.266379  \n",
      "15        0.049206        0.062684         0.264285  \n",
      "16        0.094663        0.072196         0.262209  \n",
      "17        0.110554        0.197825         0.260149  \n",
      "18        0.124519        0.061639         0.258106  \n",
      "19        0.058084        0.029302         0.256079  \n",
      "20        0.051386        0.165529         0.254068  \n",
      "21        0.045411        0.044632         0.252074  \n",
      "22        0.043961        0.132557         0.250096  \n",
      "23        0.096762        0.037319         0.248134  \n",
      "24        0.094833        0.046654         0.246188  \n",
      "25        0.041861        0.041614         0.244257  \n",
      "26        0.069011        0.101818         0.242342  \n",
      "27        0.109291        0.126639         0.240442  \n",
      "28        0.069639        0.043721         0.238557  \n",
      "29        0.054810        0.054026         0.368236  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "age_column = 'age'\n",
    "age_groups = train_df[age_column] // 10 * 10\n",
    "unique_age_groups = age_groups.unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[age_groups == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[str(age_group)]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data[age_column]\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5,greedy_ratio=0,inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}-{age_group+9}, MSE: {mse}, Model saved as: {model_filename}\")\n",
    "\n",
    "    # Save feature importances\n",
    "    feature_importance = model.explain_global().data()\n",
    "    feature_importance_df = pd.DataFrame(feature_importance['scores'][:30], columns=[f'Age Group {age_group}'])\n",
    "    feature_importance_matrix = pd.concat([feature_importance_matrix, feature_importance_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Print the feature importance matrix\n",
    "print(feature_importance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba70d5-1fe6-4754-8aac-237d18101d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return str((age // 10) * 10)\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = group_data.columns.drop(['age', 'age_group'])\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0.0', '10.0', '20.0', '30.0', '40.0', '50.0', '60.0', '70.0', '80.0', '90.0', '100.0']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "        #print(age_group in age_group_models)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare Train using top 30 features\n",
    "def prepare_train_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "\n",
    "X_test, y_test = prepare_train_data(test_data, top_30_features)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        \n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        #print(age_group,age_group_models,'make prediction')\n",
    "        final_predictions.append(prediction)\n",
    "\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred, squared=True)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970d980-3292-4b95-b7d9-e4fad44d94f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cccba44-efb3-423f-a6f3-e2f49f3c629c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e76b93-7c14-491b-b173-00bf30fbeb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
