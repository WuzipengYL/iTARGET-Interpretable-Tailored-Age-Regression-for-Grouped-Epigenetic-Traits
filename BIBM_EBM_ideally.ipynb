{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716c6aee-c28e-4449-9159-d8c7d8fe1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "\n",
    "# Ensure the age group keys are strings\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "def split_data_by_age_cv(df, age_column='age', n_splits=5, random_state=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    age_groups = df.groupby(df[age_column] // 10 * 10)\n",
    "    \n",
    "    fold_data = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_list = []\n",
    "        test_list = []\n",
    "        \n",
    "        for _, group in age_groups:\n",
    "            group_train_index = [idx for idx in train_index if idx in group.index]\n",
    "            group_test_index = [idx for idx in test_index if idx in group.index]\n",
    "            \n",
    "            train = group.loc[group_train_index]\n",
    "            test = group.loc[group_test_index]\n",
    "            \n",
    "            train_list.append(train)\n",
    "            test_list.append(test)\n",
    "        \n",
    "        train_df = pd.concat(train_list, ignore_index=True)\n",
    "        test_df = pd.concat(test_list, ignore_index=True)\n",
    "        \n",
    "        fold_data.append((train_df, test_df))\n",
    "    \n",
    "    return fold_data\n",
    "\n",
    "# Example usage\n",
    "imputed_data = pd.read_csv('imputed_data.csv',index_col =0)  # Replace with your actual data\n",
    "fold_data = split_data_by_age_cv(imputed_data)\n",
    "\n",
    "# Plotting the age distribution for the first fold's train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812d66a-04f4-49ac-a947-baa6240921f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa8034c-a81b-47d4-bada-209e6b6e8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = fold_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca55f96-9032-4071-a094-e6ec2d423a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.6411\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       158\n",
      "          10       0.98      0.98      0.98       408\n",
      "          20       0.68      0.70      0.69       139\n",
      "          30       0.53      0.48      0.50       229\n",
      "          40       0.55      0.68      0.61       433\n",
      "          50       0.51      0.56      0.53       467\n",
      "          60       0.50      0.46      0.48       360\n",
      "          70       0.54      0.28      0.37       143\n",
      "          80       0.40      0.05      0.09        38\n",
      "          90       0.50      0.17      0.25         6\n",
      "         100       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.64      2382\n",
      "   macro avg       0.56      0.49      0.50      2382\n",
      "weighted avg       0.64      0.64      0.63      2382\n",
      "\n",
      "      Actual Age Group  Predicted Age Group\n",
      "0                    0                    0\n",
      "1                    0                    0\n",
      "2                    0                    0\n",
      "3                    0                    0\n",
      "4                    0                    0\n",
      "...                ...                  ...\n",
      "2377                90                   60\n",
      "2378                90                   80\n",
      "2379                90                   80\n",
      "2380                90                   70\n",
      "2381               100                   90\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return (age // 10) * 10\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age'] // 10 * 10\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features =  group_data.drop(['age','age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=np.int32))\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065532bf-9f43-499c-9462-02d6ab04a121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(566, 30)\n",
      "Age Group: 0.0-9.0, MSE: 0.0545810401538887, Model saved as: models\\Ideal_EBM_model_age_group_0.0.joblib\n",
      "(1709, 30)\n",
      "Age Group: 10.0-19.0, MSE: 0.10429694656555655, Model saved as: models\\Ideal_EBM_model_age_group_10.0.joblib\n",
      "(586, 30)\n",
      "Age Group: 20.0-29.0, MSE: 2.5203286411127617, Model saved as: models\\Ideal_EBM_model_age_group_20.0.joblib\n",
      "(874, 30)\n",
      "Age Group: 30.0-39.0, MSE: 3.2319877928342104, Model saved as: models\\Ideal_EBM_model_age_group_30.0.joblib\n",
      "(1748, 30)\n",
      "Age Group: 40.0-49.0, MSE: 4.188095087019111, Model saved as: models\\Ideal_EBM_model_age_group_40.0.joblib\n",
      "(1945, 30)\n",
      "Age Group: 50.0-59.0, MSE: 5.376526024245087, Model saved as: models\\Ideal_EBM_model_age_group_50.0.joblib\n",
      "(1368, 30)\n",
      "Age Group: 60.0-69.0, MSE: 4.982540509435378, Model saved as: models\\Ideal_EBM_model_age_group_60.0.joblib\n",
      "(573, 30)\n",
      "Age Group: 70.0-79.0, MSE: 4.403285354980591, Model saved as: models\\Ideal_EBM_model_age_group_70.0.joblib\n",
      "(131, 30)\n",
      "Age Group: 80.0-89.0, MSE: 2.7844903375047907, Model saved as: models\\Ideal_EBM_model_age_group_80.0.joblib\n",
      "(26, 30)\n",
      "Age Group: 90.0-99.0, MSE: 0.47156552658976675, Model saved as: models\\Ideal_EBM_model_age_group_90.0.joblib\n",
      "(2, 30)\n",
      "Age Group: 100.0-109.0, MSE: 2784.4540816326544, Model saved as: models\\Ideal_EBM_model_age_group_100.0.joblib\n",
      "    Age Group 0.0  Age Group 10.0  Age Group 20.0  Age Group 30.0  \\\n",
      "0        0.085125        0.034401        0.221806        0.362298   \n",
      "1        0.083383        0.039939        0.167735        0.162785   \n",
      "2        0.085169        0.007146        0.082110        0.146272   \n",
      "3        0.081385        0.006826        0.117115        0.153221   \n",
      "4        0.091000        0.021456        0.070380        0.030342   \n",
      "5        0.118637        0.027576        0.096797        0.089669   \n",
      "6        0.080244        0.011118        0.189242        0.122468   \n",
      "7        0.101513        0.023609        0.085878        0.075661   \n",
      "8        0.087574        0.027305        0.501316        0.148450   \n",
      "9        0.069494        0.013777        0.050011        0.095505   \n",
      "10       0.086674        0.020307        0.046316        0.057336   \n",
      "11       0.096854        0.013550        0.051079        0.062544   \n",
      "12       0.067979        0.027105        0.044297        0.033826   \n",
      "13       0.076734        0.023709        0.046283        0.048706   \n",
      "14       0.078182        0.021432        0.086762        0.100666   \n",
      "15       0.075954        0.011301        0.114379        0.052224   \n",
      "16       0.052089        0.009707        0.152026        0.058951   \n",
      "17       0.050310        0.004465        0.046739        0.043967   \n",
      "18       0.063484        0.028873        0.042280        0.039770   \n",
      "19       0.079436        0.003927        0.112111        0.148292   \n",
      "20       0.040276        0.008166        0.206741        0.052255   \n",
      "21       0.036621        0.010722        0.102825        0.059853   \n",
      "22       0.063401        0.016067        0.046165        0.103360   \n",
      "23       0.062815        0.018346        0.229664        0.034476   \n",
      "24       0.044514        0.010332        0.115923        0.021906   \n",
      "25       0.041328        0.008919        0.100804        0.048013   \n",
      "26       0.028691        0.020360        0.117211        0.036087   \n",
      "27       0.035823        0.019369        0.069699        0.088241   \n",
      "28       0.079573        0.002754        0.132438        0.068475   \n",
      "29       0.058731        0.007848        0.047376        0.046529   \n",
      "\n",
      "    Age Group 40.0  Age Group 50.0  Age Group 60.0  Age Group 70.0  \\\n",
      "0         0.328106        0.325245        0.223131        0.055222   \n",
      "1         0.192054        0.244727        0.216020        0.124350   \n",
      "2         0.068112        0.087727        0.084154        0.149747   \n",
      "3         0.259994        0.156825        0.090840        0.054511   \n",
      "4         0.150864        0.044080        0.208788        0.056902   \n",
      "5         0.133247        0.079117        0.125613        0.072327   \n",
      "6         0.124430        0.046315        0.123397        0.040459   \n",
      "7         0.178986        0.279222        0.070767        0.058397   \n",
      "8         0.126060        0.043565        0.084449        0.049975   \n",
      "9         0.135815        0.038148        0.062281        0.031977   \n",
      "10        0.107475        0.062549        0.220069        0.120726   \n",
      "11        0.162122        0.169899        0.021674        0.043372   \n",
      "12        0.272700        0.036797        0.082346        0.032575   \n",
      "13        0.411498        0.172205        0.074036        0.087077   \n",
      "14        0.180100        0.030344        0.040838        0.082855   \n",
      "15        0.062131        0.046619        0.038912        0.038691   \n",
      "16        0.084885        0.054129        0.054682        0.076758   \n",
      "17        0.060077        0.044945        0.032214        0.136886   \n",
      "18        0.085843        0.028913        0.057340        0.036212   \n",
      "19        0.037530        0.035835        0.078486        0.015435   \n",
      "20        0.140815        0.030099        0.064772        0.026226   \n",
      "21        0.072209        0.040583        0.020613        0.024620   \n",
      "22        0.103812        0.050595        0.037150        0.063529   \n",
      "23        0.079502        0.027370        0.129818        0.042363   \n",
      "24        0.110338        0.041573        0.050086        0.026010   \n",
      "25        0.050850        0.031979        0.043596        0.051895   \n",
      "26        0.040930        0.033184        0.048257        0.037444   \n",
      "27        0.076751        0.039635        0.045467        0.023243   \n",
      "28        0.038087        0.052457        0.033673        0.042665   \n",
      "29        0.062138        0.046538        0.037188        0.067106   \n",
      "\n",
      "    Age Group 80.0  Age Group 90.0  Age Group 100.0  \n",
      "0         0.119878        0.159707         0.579003  \n",
      "1         0.044379        0.139568         0.573213  \n",
      "2         0.115989        0.057969         0.567481  \n",
      "3         0.035424        0.070558         0.561806  \n",
      "4         0.095958        0.056383         0.556188  \n",
      "5         0.046718        0.134426         0.550626  \n",
      "6         0.063252        0.100631         0.545120  \n",
      "7         0.041044        0.055857         0.539669  \n",
      "8         0.079787        0.036752         0.534272  \n",
      "9         0.066517        0.063633         0.528929  \n",
      "10        0.051369        0.079028         0.523640  \n",
      "11        0.074606        0.079612         0.518404  \n",
      "12        0.065499        0.044194         0.513220  \n",
      "13        0.079239        0.125659         0.508087  \n",
      "14        0.071017        0.067837         0.503007  \n",
      "15        0.030653        0.041572         0.497976  \n",
      "16        0.030342        0.040025         0.492997  \n",
      "17        0.076843        0.072001         0.488067  \n",
      "18        0.049929        0.090876         0.483186  \n",
      "19        0.024332        0.049988         0.478354  \n",
      "20        0.053962        0.128119         0.473571  \n",
      "21        0.046393        0.031720         0.468835  \n",
      "22        0.029520        0.058298         0.464147  \n",
      "23        0.035310        0.033263         0.459505  \n",
      "24        0.052957        0.035161         0.454910  \n",
      "25        0.060887        0.035185         0.450361  \n",
      "26        0.041479        0.061495         0.445857  \n",
      "27        0.078302        0.066976         0.441399  \n",
      "28        0.044430        0.023345         0.436985  \n",
      "29        0.029570        0.065790         0.432615  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "age_column = 'age'\n",
    "age_groups = train_df[age_column] // 10 * 10\n",
    "unique_age_groups = age_groups.unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[age_groups == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[str(age_group)]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data[age_column]\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5,greedy_ratio=0,inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}-{age_group+9}, MSE: {mse}, Model saved as: {model_filename}\")\n",
    "\n",
    "    # Save feature importances\n",
    "    feature_importance = model.explain_global().data()\n",
    "    feature_importance_df = pd.DataFrame(feature_importance['scores'][:30], columns=[f'Age Group {age_group}'])\n",
    "    feature_importance_matrix = pd.concat([feature_importance_matrix, feature_importance_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Print the feature importance matrix\n",
    "print(feature_importance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17be6aa7-9450-43af-96ef-d3e9997ea980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (MSE) on Test Data: 2.8632\n",
      "Mean Absolute Error (MAE) on Test Data: 1.5932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "train_data = train_df\n",
    "test_data = test_df\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "\n",
    "# Ensure the age group keys are strings\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return str((age // 10) * 10)\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Train and Test Data using top 30 features\n",
    "def prepare_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_df, top_30_features)\n",
    "X_test, y_test = prepare_data(test_df, top_30_features)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0.0', '10.0', '20.0', '30.0', '40.0', '50.0', '60.0', '70.0', '80.0', '90.0', '100.0']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "    else:\n",
    "        final_predictions.append(np.nan)  # Handle cases where there is no model for the predicted age group\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred, squared=True)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (MSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e92426-dac0-461c-a0e8-ee2683ab4410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14ba02a-7327-4fdc-ad96-3fe69cc39dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = fold_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b6ea755-c71c-4294-b70f-9d5f89d6a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.6746\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       143\n",
      "          10       0.96      0.95      0.96       458\n",
      "          20       0.65      0.73      0.69       146\n",
      "          30       0.61      0.48      0.54       220\n",
      "          40       0.57      0.72      0.64       422\n",
      "          50       0.57      0.61      0.59       465\n",
      "          60       0.55      0.53      0.54       335\n",
      "          70       0.54      0.31      0.40       150\n",
      "          80       0.33      0.03      0.05        34\n",
      "          90       1.00      0.25      0.40         8\n",
      "         100       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67      2382\n",
      "   macro avg       0.62      0.51      0.53      2382\n",
      "weighted avg       0.67      0.67      0.67      2382\n",
      "\n",
      "      Actual Age Group  Predicted Age Group\n",
      "0                    0                    0\n",
      "1                    0                    0\n",
      "2                    0                    0\n",
      "3                    0                    0\n",
      "4                    0                    0\n",
      "...                ...                  ...\n",
      "2377                90                   90\n",
      "2378                90                   90\n",
      "2379                90                   80\n",
      "2380                90                   70\n",
      "2381               100                   60\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return (age // 10) * 10\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age'] // 10 * 10\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features =  group_data.drop(['age','age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=np.int32))\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819cced7-b8c6-4212-b389-adaa01578037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581, 30)\n",
      "Age Group: 0.0-9.0, MSE: 0.06602269322060604, Model saved as: models\\Ideal_EBM_model_age_group_0.0.joblib\n",
      "(1659, 30)\n",
      "Age Group: 10.0-19.0, MSE: 0.09512053998898681, Model saved as: models\\Ideal_EBM_model_age_group_10.0.joblib\n",
      "(579, 30)\n",
      "Age Group: 20.0-29.0, MSE: 2.4967405305797254, Model saved as: models\\Ideal_EBM_model_age_group_20.0.joblib\n",
      "(883, 30)\n",
      "Age Group: 30.0-39.0, MSE: 3.5524457014326747, Model saved as: models\\Ideal_EBM_model_age_group_30.0.joblib\n",
      "(1759, 30)\n",
      "Age Group: 40.0-49.0, MSE: 4.0147832700806845, Model saved as: models\\Ideal_EBM_model_age_group_40.0.joblib\n",
      "(1947, 30)\n",
      "Age Group: 50.0-59.0, MSE: 5.613695670340837, Model saved as: models\\Ideal_EBM_model_age_group_50.0.joblib\n",
      "(1393, 30)\n",
      "Age Group: 60.0-69.0, MSE: 5.04257782997572, Model saved as: models\\Ideal_EBM_model_age_group_60.0.joblib\n",
      "(566, 30)\n",
      "Age Group: 70.0-79.0, MSE: 3.841320710284491, Model saved as: models\\Ideal_EBM_model_age_group_70.0.joblib\n",
      "(135, 30)\n",
      "Age Group: 80.0-89.0, MSE: 1.2171679011484988, Model saved as: models\\Ideal_EBM_model_age_group_80.0.joblib\n",
      "(24, 30)\n",
      "Age Group: 90.0-99.0, MSE: 0.42796796755441346, Model saved as: models\\Ideal_EBM_model_age_group_90.0.joblib\n",
      "(2, 30)\n",
      "Age Group: 100.0-109.0, MSE: 2745.614795918369, Model saved as: models\\Ideal_EBM_model_age_group_100.0.joblib\n",
      "    Age Group 0.0  Age Group 10.0  Age Group 20.0  Age Group 30.0  \\\n",
      "0        0.096732        0.029389        0.211924        0.349868   \n",
      "1        0.091068        0.035289        0.149336        0.161704   \n",
      "2        0.077510        0.010168        0.114610        0.131530   \n",
      "3        0.073010        0.007686        0.121830        0.166210   \n",
      "4        0.088407        0.014450        0.043355        0.031914   \n",
      "5        0.110070        0.016940        0.072679        0.083640   \n",
      "6        0.069124        0.012109        0.213490        0.139326   \n",
      "7        0.090698        0.019431        0.084217        0.035897   \n",
      "8        0.083526        0.018662        0.480971        0.124636   \n",
      "9        0.068351        0.012268        0.041132        0.038332   \n",
      "10       0.085685        0.018931        0.033349        0.038532   \n",
      "11       0.101588        0.020395        0.063459        0.040740   \n",
      "12       0.076017        0.024766        0.049683        0.024209   \n",
      "13       0.084027        0.022726        0.041948        0.064078   \n",
      "14       0.081390        0.017383        0.074889        0.046483   \n",
      "15       0.075668        0.013737        0.085901        0.040566   \n",
      "16       0.063927        0.008832        0.158349        0.063720   \n",
      "17       0.050595        0.005504        0.021678        0.042710   \n",
      "18       0.061576        0.025451        0.074248        0.024273   \n",
      "19       0.080662        0.013202        0.097888        0.108734   \n",
      "20       0.043723        0.005287        0.148296        0.059303   \n",
      "21       0.038036        0.008804        0.114635        0.055396   \n",
      "22       0.059353        0.011149        0.024446        0.068921   \n",
      "23       0.066720        0.014876        0.217861        0.036763   \n",
      "24       0.048388        0.007128        0.118647        0.029431   \n",
      "25       0.040735        0.008702        0.084705        0.058240   \n",
      "26       0.040096        0.010738        0.125369        0.044884   \n",
      "27       0.038699        0.013848        0.062139        0.067803   \n",
      "28       0.071700        0.003786        0.110073        0.062877   \n",
      "29       0.066133        0.004354        0.064447        0.036816   \n",
      "\n",
      "    Age Group 40.0  Age Group 50.0  Age Group 60.0  Age Group 70.0  \\\n",
      "0         0.346323        0.285621        0.213276        0.076610   \n",
      "1         0.171301        0.208863        0.207965        0.135164   \n",
      "2         0.131739        0.120443        0.077006        0.252027   \n",
      "3         0.280643        0.177127        0.079800        0.057625   \n",
      "4         0.172458        0.066010        0.237643        0.054535   \n",
      "5         0.111667        0.077090        0.152431        0.081285   \n",
      "6         0.091739        0.054582        0.164741        0.061702   \n",
      "7         0.178639        0.248278        0.032945        0.067521   \n",
      "8         0.095458        0.049186        0.070034        0.069760   \n",
      "9         0.164308        0.031344        0.075706        0.078553   \n",
      "10        0.133433        0.049692        0.221629        0.184279   \n",
      "11        0.170955        0.174339        0.033361        0.029016   \n",
      "12        0.223494        0.032659        0.059518        0.045638   \n",
      "13        0.410939        0.156389        0.057134        0.082797   \n",
      "14        0.186223        0.027652        0.026619        0.123189   \n",
      "15        0.058050        0.030543        0.045967        0.044436   \n",
      "16        0.081732        0.053744        0.098476        0.051198   \n",
      "17        0.072594        0.020330        0.035674        0.216819   \n",
      "18        0.095987        0.019015        0.061311        0.040776   \n",
      "19        0.064862        0.041416        0.094645        0.027236   \n",
      "20        0.121347        0.025579        0.049873        0.046419   \n",
      "21        0.063606        0.019408        0.048108        0.039679   \n",
      "22        0.079811        0.022586        0.059574        0.100605   \n",
      "23        0.089826        0.017953        0.104678        0.038810   \n",
      "24        0.148801        0.022641        0.075851        0.063004   \n",
      "25        0.050405        0.029059        0.034012        0.043392   \n",
      "26        0.057860        0.028383        0.047489        0.034554   \n",
      "27        0.092550        0.043108        0.041958        0.022607   \n",
      "28        0.031980        0.056167        0.055308        0.057081   \n",
      "29        0.045355        0.039541        0.054106        0.082365   \n",
      "\n",
      "    Age Group 80.0  Age Group 90.0  Age Group 100.0  \n",
      "0         0.100512        0.204313         0.541958  \n",
      "1         0.034317        0.137576         0.536538  \n",
      "2         0.094857        0.086757         0.531173  \n",
      "3         0.038575        0.063572         0.525861  \n",
      "4         0.120392        0.063082         0.520603  \n",
      "5         0.070960        0.093961         0.515397  \n",
      "6         0.085318        0.086540         0.510243  \n",
      "7         0.036826        0.086391         0.505140  \n",
      "8         0.122063        0.056048         0.500089  \n",
      "9         0.056718        0.072836         0.495088  \n",
      "10        0.095988        0.059296         0.490137  \n",
      "11        0.081091        0.153842         0.485236  \n",
      "12        0.093293        0.053386         0.480383  \n",
      "13        0.084663        0.182885         0.475579  \n",
      "14        0.079514        0.055004         0.470824  \n",
      "15        0.040058        0.040651         0.466115  \n",
      "16        0.040117        0.056791         0.461454  \n",
      "17        0.098264        0.079754         0.456840  \n",
      "18        0.094106        0.106097         0.452271  \n",
      "19        0.042834        0.050132         0.447749  \n",
      "20        0.107136        0.103743         0.443271  \n",
      "21        0.101312        0.048675         0.438838  \n",
      "22        0.017945        0.077354         0.434450  \n",
      "23        0.079812        0.044661         0.430105  \n",
      "24        0.071518        0.049059         0.425804  \n",
      "25        0.058455        0.061989         0.421546  \n",
      "26        0.048692        0.083451         0.417331  \n",
      "27        0.078504        0.097037         0.413158  \n",
      "28        0.074051        0.047269         0.409026  \n",
      "29        0.065388        0.053450         0.404936  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "age_column = 'age'\n",
    "age_groups = train_df[age_column] // 10 * 10\n",
    "unique_age_groups = age_groups.unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[age_groups == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[str(age_group)]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data[age_column]\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5,greedy_ratio=0,inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}-{age_group+9}, MSE: {mse}, Model saved as: {model_filename}\")\n",
    "\n",
    "    # Save feature importances\n",
    "    feature_importance = model.explain_global().data()\n",
    "    feature_importance_df = pd.DataFrame(feature_importance['scores'][:30], columns=[f'Age Group {age_group}'])\n",
    "    feature_importance_matrix = pd.concat([feature_importance_matrix, feature_importance_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Print the feature importance matrix\n",
    "print(feature_importance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0732634-c92e-47aa-a13a-4c29f01c7b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (MSE) on Test Data: 2.9176\n",
      "Mean Absolute Error (MAE) on Test Data: 1.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "train_data = train_df\n",
    "test_data = test_df\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "\n",
    "# Ensure the age group keys are strings\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return str((age // 10) * 10)\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Train and Test Data using top 30 features\n",
    "def prepare_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_df, top_30_features)\n",
    "X_test, y_test = prepare_data(test_df, top_30_features)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0.0', '10.0', '20.0', '30.0', '40.0', '50.0', '60.0', '70.0', '80.0', '90.0', '100.0']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "    else:\n",
    "        final_predictions.append(np.nan)  # Handle cases where there is no model for the predicted age group\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred, squared=True)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (MSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357033e9-40b7-4053-9b1c-a446ceb0c707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046f090c-508b-4673-89f8-32a0a59d5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = fold_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce23706-ed19-418e-9a2a-7951d4056b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.6763\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       144\n",
      "          10       0.96      0.97      0.97       439\n",
      "          20       0.73      0.79      0.75       135\n",
      "          30       0.63      0.51      0.57       220\n",
      "          40       0.59      0.71      0.64       441\n",
      "          50       0.55      0.62      0.58       478\n",
      "          60       0.55      0.48      0.51       348\n",
      "          70       0.49      0.34      0.40       137\n",
      "          80       0.50      0.09      0.15        34\n",
      "          90       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.68      2382\n",
      "   macro avg       0.65      0.57      0.58      2382\n",
      "weighted avg       0.67      0.68      0.67      2382\n",
      "\n",
      "      Actual Age Group  Predicted Age Group\n",
      "0                    0                    0\n",
      "1                    0                    0\n",
      "2                    0                    0\n",
      "3                    0                    0\n",
      "4                    0                    0\n",
      "...                ...                  ...\n",
      "2377                90                   60\n",
      "2378                90                   90\n",
      "2379                90                   80\n",
      "2380                90                   70\n",
      "2381                90                   70\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return (age // 10) * 10\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age'] // 10 * 10\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features =  group_data.drop(['age','age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=np.int32))\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7369a8b1-e3ee-4c44-8698-296bbd4aaa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 30)\n",
      "Age Group: 0.0-9.0, MSE: 0.042341642761241194, Model saved as: models\\Ideal_EBM_model_age_group_0.0.joblib\n",
      "(1678, 30)\n",
      "Age Group: 10.0-19.0, MSE: 0.10885931919553064, Model saved as: models\\Ideal_EBM_model_age_group_10.0.joblib\n",
      "(590, 30)\n",
      "Age Group: 20.0-29.0, MSE: 2.331794442086963, Model saved as: models\\Ideal_EBM_model_age_group_20.0.joblib\n",
      "(883, 30)\n",
      "Age Group: 30.0-39.0, MSE: 3.6748995289001707, Model saved as: models\\Ideal_EBM_model_age_group_30.0.joblib\n",
      "(1740, 30)\n",
      "Age Group: 40.0-49.0, MSE: 4.058645864204199, Model saved as: models\\Ideal_EBM_model_age_group_40.0.joblib\n",
      "(1934, 30)\n",
      "Age Group: 50.0-59.0, MSE: 5.447007897244662, Model saved as: models\\Ideal_EBM_model_age_group_50.0.joblib\n",
      "(1380, 30)\n",
      "Age Group: 60.0-69.0, MSE: 5.06237274529167, Model saved as: models\\Ideal_EBM_model_age_group_60.0.joblib\n",
      "(579, 30)\n",
      "Age Group: 70.0-79.0, MSE: 3.64156622804192, Model saved as: models\\Ideal_EBM_model_age_group_70.0.joblib\n",
      "(135, 30)\n",
      "Age Group: 80.0-89.0, MSE: 2.1349249607809737, Model saved as: models\\Ideal_EBM_model_age_group_80.0.joblib\n",
      "(26, 30)\n",
      "Age Group: 90.0-99.0, MSE: 0.5012178603326414, Model saved as: models\\Ideal_EBM_model_age_group_90.0.joblib\n",
      "(3, 30)\n",
      "Age Group: 100.0-109.0, MSE: 1167.6968980975703, Model saved as: models\\Ideal_EBM_model_age_group_100.0.joblib\n",
      "    Age Group 0.0  Age Group 10.0  Age Group 20.0  Age Group 30.0  \\\n",
      "0        0.093697        0.029631        0.190449        0.333075   \n",
      "1        0.097846        0.031306        0.141369        0.163440   \n",
      "2        0.074294        0.008271        0.063331        0.118141   \n",
      "3        0.076124        0.007703        0.113274        0.172398   \n",
      "4        0.090229        0.020130        0.102217        0.022308   \n",
      "5        0.117665        0.018636        0.100459        0.089474   \n",
      "6        0.078064        0.011860        0.276415        0.137615   \n",
      "7        0.099296        0.013083        0.068554        0.048362   \n",
      "8        0.091558        0.025974        0.553721        0.129723   \n",
      "9        0.069766        0.016964        0.039805        0.062967   \n",
      "10       0.093577        0.020463        0.059554        0.029094   \n",
      "11       0.111289        0.017660        0.056949        0.035875   \n",
      "12       0.074132        0.020824        0.031606        0.035923   \n",
      "13       0.088760        0.021564        0.055655        0.064902   \n",
      "14       0.099792        0.017143        0.071962        0.054678   \n",
      "15       0.068543        0.015599        0.081491        0.041968   \n",
      "16       0.060762        0.013192        0.169362        0.071552   \n",
      "17       0.044465        0.007945        0.038152        0.032377   \n",
      "18       0.060108        0.017785        0.087905        0.025183   \n",
      "19       0.071072        0.006860        0.116751        0.084988   \n",
      "20       0.045125        0.006569        0.121109        0.037302   \n",
      "21       0.036689        0.008415        0.115879        0.063914   \n",
      "22       0.062997        0.012560        0.048116        0.056411   \n",
      "23       0.070823        0.007040        0.173452        0.035012   \n",
      "24       0.053867        0.007547        0.148673        0.035315   \n",
      "25       0.037486        0.010946        0.086761        0.036073   \n",
      "26       0.038285        0.015843        0.116024        0.023628   \n",
      "27       0.040430        0.014685        0.030320        0.072617   \n",
      "28       0.075115        0.003609        0.120261        0.048883   \n",
      "29       0.064853        0.003150        0.054492        0.029249   \n",
      "\n",
      "    Age Group 40.0  Age Group 50.0  Age Group 60.0  Age Group 70.0  \\\n",
      "0         0.342063        0.302463        0.218712        0.051302   \n",
      "1         0.192369        0.225988        0.183938        0.116988   \n",
      "2         0.111188        0.079000        0.067463        0.249069   \n",
      "3         0.245333        0.187816        0.080927        0.050033   \n",
      "4         0.181184        0.062488        0.239580        0.100204   \n",
      "5         0.095302        0.114958        0.159108        0.062512   \n",
      "6         0.099411        0.048012        0.150690        0.091405   \n",
      "7         0.176144        0.269845        0.076183        0.052041   \n",
      "8         0.084743        0.056961        0.087414        0.105077   \n",
      "9         0.189216        0.035921        0.082452        0.077939   \n",
      "10        0.150305        0.064239        0.217718        0.112262   \n",
      "11        0.163002        0.168120        0.016482        0.037464   \n",
      "12        0.223407        0.030502        0.054908        0.069364   \n",
      "13        0.439533        0.171146        0.076944        0.080522   \n",
      "14        0.187865        0.021771        0.036139        0.109771   \n",
      "15        0.066719        0.036959        0.056618        0.032313   \n",
      "16        0.075027        0.073104        0.101967        0.087583   \n",
      "17        0.060364        0.027972        0.028038        0.214003   \n",
      "18        0.099147        0.025159        0.038289        0.026873   \n",
      "19        0.070457        0.038172        0.063792        0.032187   \n",
      "20        0.142793        0.024971        0.093595        0.063820   \n",
      "21        0.063282        0.026006        0.022736        0.025011   \n",
      "22        0.111551        0.011321        0.053182        0.153902   \n",
      "23        0.085263        0.032497        0.103993        0.037239   \n",
      "24        0.149453        0.022760        0.088734        0.048263   \n",
      "25        0.063071        0.030071        0.054779        0.050339   \n",
      "26        0.046660        0.020356        0.066577        0.051648   \n",
      "27        0.102104        0.049317        0.057642        0.048552   \n",
      "28        0.026940        0.059040        0.044291        0.111166   \n",
      "29        0.068069        0.046201        0.047492        0.053443   \n",
      "\n",
      "    Age Group 80.0  Age Group 90.0  Age Group 100.0  \n",
      "0         0.109471        0.255465         0.297540  \n",
      "1         0.048756        0.150639         0.295195  \n",
      "2         0.186437        0.062057         0.292869  \n",
      "3         0.029761        0.051372         0.290562  \n",
      "4         0.119664        0.092719         0.288273  \n",
      "5         0.044056        0.121506         0.286003  \n",
      "6         0.118931        0.144692         0.283751  \n",
      "7         0.034077        0.083738         0.281517  \n",
      "8         0.134317        0.057806         0.279302  \n",
      "9         0.095660        0.087288         0.277104  \n",
      "10        0.063672        0.066856         0.274924  \n",
      "11        0.070889        0.151413         0.272762  \n",
      "12        0.107294        0.077110         0.270617  \n",
      "13        0.101859        0.172435         0.268489  \n",
      "14        0.107503        0.081294         0.266379  \n",
      "15        0.028561        0.032420         0.264285  \n",
      "16        0.068476        0.052406         0.262209  \n",
      "17        0.063765        0.114745         0.260149  \n",
      "18        0.095478        0.095666         0.258106  \n",
      "19        0.071048        0.045287         0.256079  \n",
      "20        0.027459        0.129254         0.254068  \n",
      "21        0.041692        0.075313         0.252074  \n",
      "22        0.030288        0.112434         0.250096  \n",
      "23        0.048877        0.067510         0.248134  \n",
      "24        0.078142        0.026533         0.246188  \n",
      "25        0.063494        0.086880         0.244257  \n",
      "26        0.058398        0.071506         0.242342  \n",
      "27        0.073975        0.127668         0.240442  \n",
      "28        0.046154        0.029448         0.238557  \n",
      "29        0.064918        0.048450         0.368236  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "age_column = 'age'\n",
    "age_groups = train_df[age_column] // 10 * 10\n",
    "unique_age_groups = age_groups.unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[age_groups == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[str(age_group)]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data[age_column]\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5,greedy_ratio=0,inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}-{age_group+9}, MSE: {mse}, Model saved as: {model_filename}\")\n",
    "\n",
    "    # Save feature importances\n",
    "    feature_importance = model.explain_global().data()\n",
    "    feature_importance_df = pd.DataFrame(feature_importance['scores'][:30], columns=[f'Age Group {age_group}'])\n",
    "    feature_importance_matrix = pd.concat([feature_importance_matrix, feature_importance_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Print the feature importance matrix\n",
    "print(feature_importance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8889f16-0000-41a2-9356-375b928e38de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (MSE) on Test Data: 2.1248\n",
      "Mean Absolute Error (MAE) on Test Data: 1.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "train_data = train_df\n",
    "test_data = test_df\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "\n",
    "# Ensure the age group keys are strings\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return str((age // 10) * 10)\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Train and Test Data using top 30 features\n",
    "def prepare_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_df, top_30_features)\n",
    "X_test, y_test = prepare_data(test_df, top_30_features)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0.0', '10.0', '20.0', '30.0', '40.0', '50.0', '60.0', '70.0', '80.0', '90.0', '100.0']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "    else:\n",
    "        final_predictions.append(np.nan)  # Handle cases where there is no model for the predicted age group\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred, squared=True)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (MSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23760acd-dec3-4253-a548-bcd26f5929e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5854fb60-79d1-4083-b052-75411b82b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = fold_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b63a7fa-5da6-49f4-9fcf-a8ae69650fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.6511\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       135\n",
      "          10       0.93      0.96      0.95       399\n",
      "          20       0.71      0.64      0.67       154\n",
      "          30       0.53      0.48      0.50       208\n",
      "          40       0.56      0.70      0.62       445\n",
      "          50       0.55      0.60      0.58       514\n",
      "          60       0.55      0.49      0.52       349\n",
      "          70       0.51      0.27      0.35       138\n",
      "          80       1.00      0.09      0.17        33\n",
      "          90       0.67      0.33      0.44         6\n",
      "         100       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.65      2382\n",
      "   macro avg       0.64      0.51      0.53      2382\n",
      "weighted avg       0.65      0.65      0.64      2382\n",
      "\n",
      "      Actual Age Group  Predicted Age Group\n",
      "0                    0                    0\n",
      "1                    0                    0\n",
      "2                    0                    0\n",
      "3                    0                    0\n",
      "4                    0                    0\n",
      "...                ...                  ...\n",
      "2377                90                   90\n",
      "2378                90                   60\n",
      "2379                90                   60\n",
      "2380                90                   70\n",
      "2381               100                   70\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return (age // 10) * 10\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age'] // 10 * 10\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features =  group_data.drop(['age','age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=np.int32))\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae29dd18-5c7c-41bf-ac46-5c225dee42c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589, 30)\n",
      "Age Group: 0.0-9.0, MSE: 0.07738011757171012, Model saved as: models\\Ideal_EBM_model_age_group_0.0.joblib\n",
      "(1718, 30)\n",
      "Age Group: 10.0-19.0, MSE: 0.09798220634201169, Model saved as: models\\Ideal_EBM_model_age_group_10.0.joblib\n",
      "(571, 30)\n",
      "Age Group: 20.0-29.0, MSE: 2.497704711720544, Model saved as: models\\Ideal_EBM_model_age_group_20.0.joblib\n",
      "(895, 30)\n",
      "Age Group: 30.0-39.0, MSE: 3.4647387492757304, Model saved as: models\\Ideal_EBM_model_age_group_30.0.joblib\n",
      "(1736, 30)\n",
      "Age Group: 40.0-49.0, MSE: 4.139902011352934, Model saved as: models\\Ideal_EBM_model_age_group_40.0.joblib\n",
      "(1898, 30)\n",
      "Age Group: 50.0-59.0, MSE: 5.456337039752191, Model saved as: models\\Ideal_EBM_model_age_group_50.0.joblib\n",
      "(1379, 30)\n",
      "Age Group: 60.0-69.0, MSE: 5.141985591529512, Model saved as: models\\Ideal_EBM_model_age_group_60.0.joblib\n",
      "(578, 30)\n",
      "Age Group: 70.0-79.0, MSE: 3.7757103540006773, Model saved as: models\\Ideal_EBM_model_age_group_70.0.joblib\n",
      "(136, 30)\n",
      "Age Group: 80.0-89.0, MSE: 1.618447461319488, Model saved as: models\\Ideal_EBM_model_age_group_80.0.joblib\n",
      "(26, 30)\n",
      "Age Group: 90.0-99.0, MSE: 0.8434340913044452, Model saved as: models\\Ideal_EBM_model_age_group_90.0.joblib\n",
      "(2, 30)\n",
      "Age Group: 100.0-109.0, MSE: 2585.357878158211, Model saved as: models\\Ideal_EBM_model_age_group_100.0.joblib\n",
      "    Age Group 0.0  Age Group 10.0  Age Group 20.0  Age Group 30.0  \\\n",
      "0        0.091450        0.038316        0.167997        0.285377   \n",
      "1        0.087573        0.040414        0.138462        0.124098   \n",
      "2        0.086349        0.007682        0.093938        0.110052   \n",
      "3        0.077568        0.005258        0.075083        0.144113   \n",
      "4        0.086208        0.017502        0.079302        0.028725   \n",
      "5        0.116238        0.017604        0.104564        0.086792   \n",
      "6        0.066291        0.009294        0.230478        0.156609   \n",
      "7        0.100904        0.019987        0.089042        0.021741   \n",
      "8        0.089774        0.022271        0.576842        0.127683   \n",
      "9        0.068912        0.015509        0.069665        0.073314   \n",
      "10       0.092790        0.024106        0.046590        0.037548   \n",
      "11       0.094174        0.009344        0.069551        0.053143   \n",
      "12       0.067607        0.023195        0.035204        0.039846   \n",
      "13       0.081065        0.024114        0.051155        0.036060   \n",
      "14       0.094873        0.019743        0.062525        0.062632   \n",
      "15       0.072903        0.018716        0.079938        0.054894   \n",
      "16       0.064511        0.008451        0.176380        0.073261   \n",
      "17       0.049588        0.004834        0.043438        0.040714   \n",
      "18       0.063275        0.027934        0.068790        0.021501   \n",
      "19       0.076478        0.006880        0.111733        0.082813   \n",
      "20       0.043865        0.007985        0.121036        0.037864   \n",
      "21       0.032419        0.009382        0.102218        0.053692   \n",
      "22       0.062959        0.015286        0.078466        0.074997   \n",
      "23       0.065867        0.019781        0.192162        0.048577   \n",
      "24       0.054508        0.011575        0.095282        0.038344   \n",
      "25       0.041365        0.004541        0.115629        0.032404   \n",
      "26       0.030132        0.012574        0.086154        0.024457   \n",
      "27       0.036346        0.018377        0.044034        0.065502   \n",
      "28       0.084992        0.005349        0.113658        0.059690   \n",
      "29       0.071459        0.004049        0.039909        0.038855   \n",
      "\n",
      "    Age Group 40.0  Age Group 50.0  Age Group 60.0  Age Group 70.0  \\\n",
      "0         0.340030        0.314912        0.215895        0.065265   \n",
      "1         0.179363        0.227087        0.190705        0.163275   \n",
      "2         0.104413        0.088922        0.089166        0.263323   \n",
      "3         0.224440        0.172027        0.068593        0.061454   \n",
      "4         0.169695        0.039701        0.212465        0.131121   \n",
      "5         0.090015        0.114402        0.154432        0.027102   \n",
      "6         0.098237        0.059626        0.137117        0.065608   \n",
      "7         0.174021        0.243454        0.048888        0.047512   \n",
      "8         0.123788        0.051882        0.087889        0.076483   \n",
      "9         0.143932        0.048518        0.087110        0.067300   \n",
      "10        0.149221        0.065337        0.226766        0.173717   \n",
      "11        0.130395        0.136709        0.013613        0.055776   \n",
      "12        0.234772        0.044031        0.060681        0.051289   \n",
      "13        0.386082        0.157063        0.060606        0.049977   \n",
      "14        0.169338        0.015644        0.034306        0.130332   \n",
      "15        0.048065        0.064531        0.058901        0.059029   \n",
      "16        0.070135        0.052571        0.088457        0.120277   \n",
      "17        0.037849        0.040896        0.038903        0.217950   \n",
      "18        0.072226        0.010711        0.029518        0.044523   \n",
      "19        0.079571        0.049676        0.032144        0.043065   \n",
      "20        0.148947        0.028653        0.067550        0.035832   \n",
      "21        0.045572        0.036791        0.048024        0.054394   \n",
      "22        0.091422        0.012344        0.050848        0.097483   \n",
      "23        0.116312        0.027770        0.113049        0.052073   \n",
      "24        0.131663        0.024718        0.076333        0.055946   \n",
      "25        0.025308        0.038376        0.040110        0.066119   \n",
      "26        0.054197        0.032273        0.064974        0.047904   \n",
      "27        0.050888        0.047515        0.030310        0.042575   \n",
      "28        0.029043        0.051284        0.026421        0.076835   \n",
      "29        0.056411        0.055691        0.045249        0.064761   \n",
      "\n",
      "    Age Group 80.0  Age Group 90.0  Age Group 100.0  \n",
      "0         0.131123        0.220055         0.585863  \n",
      "1         0.033426        0.134305         0.580005  \n",
      "2         0.087039        0.034092         0.574205  \n",
      "3         0.032046        0.068417         0.568463  \n",
      "4         0.083773        0.055816         0.562778  \n",
      "5         0.035417        0.162790         0.557150  \n",
      "6         0.043319        0.119131         0.551579  \n",
      "7         0.045014        0.071448         0.546063  \n",
      "8         0.108384        0.066064         0.540602  \n",
      "9         0.040035        0.062794         0.535196  \n",
      "10        0.044105        0.077098         0.529844  \n",
      "11        0.068290        0.122402         0.524546  \n",
      "12        0.071521        0.038816         0.519300  \n",
      "13        0.077736        0.139607         0.514107  \n",
      "14        0.070533        0.044229         0.508966  \n",
      "15        0.042149        0.023282         0.503877  \n",
      "16        0.040089        0.056534         0.498838  \n",
      "17        0.080839        0.108600         0.493849  \n",
      "18        0.066547        0.070239         0.488911  \n",
      "19        0.042172        0.056672         0.484022  \n",
      "20        0.042025        0.079336         0.479182  \n",
      "21        0.041796        0.028063         0.474390  \n",
      "22        0.039765        0.105112         0.469646  \n",
      "23        0.022363        0.035858         0.464949  \n",
      "24        0.097972        0.029056         0.460300  \n",
      "25        0.073451        0.069608         0.455697  \n",
      "26        0.038426        0.081140         0.451140  \n",
      "27        0.052190        0.079296         0.446629  \n",
      "28        0.034659        0.031410         0.442162  \n",
      "29        0.044254        0.050285         0.000000  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "age_column = 'age'\n",
    "age_groups = train_df[age_column] // 10 * 10\n",
    "unique_age_groups = age_groups.unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[age_groups == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[str(age_group)]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data[age_column]\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5,greedy_ratio=0,inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}-{age_group+9}, MSE: {mse}, Model saved as: {model_filename}\")\n",
    "\n",
    "    # Save feature importances\n",
    "    feature_importance = model.explain_global().data()\n",
    "    feature_importance_df = pd.DataFrame(feature_importance['scores'][:30], columns=[f'Age Group {age_group}'])\n",
    "    feature_importance_matrix = pd.concat([feature_importance_matrix, feature_importance_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Print the feature importance matrix\n",
    "print(feature_importance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc2f78a-5091-40d6-a41e-aefcb4244952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (MSE) on Test Data: 2.8982\n",
      "Mean Absolute Error (MAE) on Test Data: 1.6045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "train_data = train_df\n",
    "test_data = test_df\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "\n",
    "# Ensure the age group keys are strings\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return str((age // 10) * 10)\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Train and Test Data using top 30 features\n",
    "def prepare_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_df, top_30_features)\n",
    "X_test, y_test = prepare_data(test_df, top_30_features)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0.0', '10.0', '20.0', '30.0', '40.0', '50.0', '60.0', '70.0', '80.0', '90.0', '100.0']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "    else:\n",
    "        final_predictions.append(np.nan)  # Handle cases where there is no model for the predicted age group\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred, squared=True)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (MSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291818ef-75fc-43b0-98e2-7f9ab48da25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d05132b-0e1c-46c8-ada0-183ff4110115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = fold_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1c629b-2633-4414-a418-efc220cb8fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.6520\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       144\n",
      "          10       0.95      0.98      0.96       413\n",
      "          20       0.70      0.70      0.70       151\n",
      "          30       0.57      0.50      0.53       226\n",
      "          40       0.55      0.68      0.61       440\n",
      "          50       0.53      0.57      0.55       488\n",
      "          60       0.53      0.48      0.51       336\n",
      "          70       0.51      0.28      0.36       148\n",
      "          80       0.80      0.13      0.23        30\n",
      "          90       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.65      2382\n",
      "   macro avg       0.66      0.55      0.57      2382\n",
      "weighted avg       0.65      0.65      0.64      2382\n",
      "\n",
      "      Actual Age Group  Predicted Age Group\n",
      "0                    0                    0\n",
      "1                    0                    0\n",
      "2                    0                    0\n",
      "3                    0                    0\n",
      "4                    0                    0\n",
      "...                ...                  ...\n",
      "2377                90                   90\n",
      "2378                90                   70\n",
      "2379                90                   70\n",
      "2380                90                   70\n",
      "2381                90                   70\n",
      "\n",
      "[2382 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return (age // 10) * 10\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Test Data using top 30 features\n",
    "def prepare_data(data):\n",
    "    age_groups = data['age'] // 10 * 10\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features =  group_data.drop(['age','age_group'], axis=1)\n",
    "        X.append(features.to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy(dtype=np.int32))\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "y_pred = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    y_pred.append(unique[np.argmax(counts)])\n",
    "\n",
    "# Evaluate Predictions\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display Prediction Errors\n",
    "error_table = pd.DataFrame({'Actual Age Group': y_test, 'Predicted Age Group': y_pred})\n",
    "print(error_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e39a42b-1976-4391-9c39-2d2353d79562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 30)\n",
      "Age Group: 0.0-9.0, MSE: 0.06115656607487444, Model saved as: models\\Ideal_EBM_model_age_group_0.0.joblib\n",
      "(1704, 30)\n",
      "Age Group: 10.0-19.0, MSE: 0.13035405091561272, Model saved as: models\\Ideal_EBM_model_age_group_10.0.joblib\n",
      "(574, 30)\n",
      "Age Group: 20.0-29.0, MSE: 2.8261296512623084, Model saved as: models\\Ideal_EBM_model_age_group_20.0.joblib\n",
      "(877, 30)\n",
      "Age Group: 30.0-39.0, MSE: 3.089915243482211, Model saved as: models\\Ideal_EBM_model_age_group_30.0.joblib\n",
      "(1741, 30)\n",
      "Age Group: 40.0-49.0, MSE: 4.161589466250099, Model saved as: models\\Ideal_EBM_model_age_group_40.0.joblib\n",
      "(1924, 30)\n",
      "Age Group: 50.0-59.0, MSE: 5.3932709817306, Model saved as: models\\Ideal_EBM_model_age_group_50.0.joblib\n",
      "(1392, 30)\n",
      "Age Group: 60.0-69.0, MSE: 4.7428774316270275, Model saved as: models\\Ideal_EBM_model_age_group_60.0.joblib\n",
      "(568, 30)\n",
      "Age Group: 70.0-79.0, MSE: 4.211032339370485, Model saved as: models\\Ideal_EBM_model_age_group_70.0.joblib\n",
      "(139, 30)\n",
      "Age Group: 80.0-89.0, MSE: 1.5930211403185164, Model saved as: models\\Ideal_EBM_model_age_group_80.0.joblib\n",
      "(26, 30)\n",
      "Age Group: 90.0-99.0, MSE: 0.27286454406202937, Model saved as: models\\Ideal_EBM_model_age_group_90.0.joblib\n",
      "(3, 30)\n",
      "Age Group: 100.0-109.0, MSE: 1167.6968980975703, Model saved as: models\\Ideal_EBM_model_age_group_100.0.joblib\n",
      "    Age Group 0.0  Age Group 10.0  Age Group 20.0  Age Group 30.0  \\\n",
      "0        0.094239        0.025142        0.190447        0.423137   \n",
      "1        0.077629        0.032502        0.143500        0.158028   \n",
      "2        0.087692        0.007632        0.060307        0.142383   \n",
      "3        0.085297        0.005184        0.117107        0.176928   \n",
      "4        0.081918        0.020781        0.074821        0.029513   \n",
      "5        0.122286        0.019343        0.109038        0.114403   \n",
      "6        0.074189        0.009641        0.220315        0.184398   \n",
      "7        0.099230        0.019168        0.068759        0.035670   \n",
      "8        0.086888        0.022453        0.609557        0.184991   \n",
      "9        0.077531        0.014310        0.071893        0.092908   \n",
      "10       0.082840        0.019401        0.071020        0.073473   \n",
      "11       0.098920        0.017130        0.034790        0.050810   \n",
      "12       0.060742        0.025398        0.047223        0.050858   \n",
      "13       0.071635        0.021739        0.056981        0.071114   \n",
      "14       0.089437        0.016998        0.071919        0.068820   \n",
      "15       0.080260        0.014069        0.053044        0.064193   \n",
      "16       0.058829        0.006501        0.162115        0.064676   \n",
      "17       0.049554        0.003479        0.032395        0.056560   \n",
      "18       0.066099        0.028267        0.060717        0.031352   \n",
      "19       0.073296        0.005479        0.118411        0.113448   \n",
      "20       0.039978        0.008685        0.113433        0.042064   \n",
      "21       0.035696        0.006338        0.104381        0.055553   \n",
      "22       0.069439        0.014535        0.036222        0.080931   \n",
      "23       0.069785        0.013492        0.218026        0.065863   \n",
      "24       0.055753        0.005235        0.128403        0.032929   \n",
      "25       0.039251        0.004085        0.058953        0.048727   \n",
      "26       0.031399        0.012503        0.156466        0.043142   \n",
      "27       0.039325        0.019866        0.052947        0.115960   \n",
      "28       0.087006        0.003684        0.091530        0.076390   \n",
      "29       0.054986        0.006032        0.046588        0.053185   \n",
      "\n",
      "    Age Group 40.0  Age Group 50.0  Age Group 60.0  Age Group 70.0  \\\n",
      "0         0.333237        0.327271        0.230681        0.056739   \n",
      "1         0.199565        0.194883        0.226366        0.195659   \n",
      "2         0.104037        0.113457        0.094752        0.189281   \n",
      "3         0.198905        0.174796        0.102264        0.086317   \n",
      "4         0.174442        0.058287        0.217348        0.085507   \n",
      "5         0.107905        0.100544        0.131095        0.088613   \n",
      "6         0.082036        0.058022        0.157773        0.113220   \n",
      "7         0.170771        0.243030        0.054309        0.060492   \n",
      "8         0.089317        0.052745        0.108106        0.101469   \n",
      "9         0.152552        0.029502        0.080686        0.075368   \n",
      "10        0.134908        0.061613        0.200575        0.175850   \n",
      "11        0.154720        0.169439        0.026357        0.027090   \n",
      "12        0.220955        0.040545        0.078325        0.036970   \n",
      "13        0.385247        0.143378        0.067052        0.091065   \n",
      "14        0.172632        0.019786        0.042591        0.136498   \n",
      "15        0.071230        0.050728        0.047492        0.074324   \n",
      "16        0.075555        0.071093        0.065569        0.073912   \n",
      "17        0.059069        0.046889        0.040429        0.208588   \n",
      "18        0.075573        0.028425        0.049715        0.021757   \n",
      "19        0.059418        0.045501        0.047720        0.045397   \n",
      "20        0.148374        0.028026        0.064843        0.052662   \n",
      "21        0.047351        0.022264        0.058868        0.044225   \n",
      "22        0.072388        0.028313        0.063613        0.113717   \n",
      "23        0.084436        0.034769        0.127498        0.053031   \n",
      "24        0.125749        0.029136        0.064044        0.045880   \n",
      "25        0.038044        0.028833        0.057305        0.050479   \n",
      "26        0.044810        0.031598        0.067569        0.055842   \n",
      "27        0.072098        0.045011        0.069484        0.026901   \n",
      "28        0.019898        0.053933        0.051007        0.056095   \n",
      "29        0.044741        0.060043        0.056388        0.090092   \n",
      "\n",
      "    Age Group 80.0  Age Group 90.0  Age Group 100.0  \n",
      "0         0.189233        0.261403         0.297540  \n",
      "1         0.070313        0.100161         0.295195  \n",
      "2         0.163476        0.057221         0.292869  \n",
      "3         0.033226        0.059816         0.290562  \n",
      "4         0.106094        0.069533         0.288273  \n",
      "5         0.065637        0.124201         0.286003  \n",
      "6         0.100621        0.165769         0.283751  \n",
      "7         0.076701        0.086122         0.281517  \n",
      "8         0.083777        0.028749         0.279302  \n",
      "9         0.068262        0.092727         0.277104  \n",
      "10        0.079379        0.071095         0.274924  \n",
      "11        0.073843        0.144519         0.272762  \n",
      "12        0.112091        0.043638         0.270617  \n",
      "13        0.156859        0.211336         0.268489  \n",
      "14        0.061977        0.105158         0.266379  \n",
      "15        0.049206        0.062684         0.264285  \n",
      "16        0.094663        0.072196         0.262209  \n",
      "17        0.110554        0.197825         0.260149  \n",
      "18        0.124519        0.061639         0.258106  \n",
      "19        0.058084        0.029302         0.256079  \n",
      "20        0.051386        0.165529         0.254068  \n",
      "21        0.045411        0.044632         0.252074  \n",
      "22        0.043961        0.132557         0.250096  \n",
      "23        0.096762        0.037319         0.248134  \n",
      "24        0.094833        0.046654         0.246188  \n",
      "25        0.041861        0.041614         0.244257  \n",
      "26        0.069011        0.101818         0.242342  \n",
      "27        0.109291        0.126639         0.240442  \n",
      "28        0.069639        0.043721         0.238557  \n",
      "29        0.054810        0.054026         0.368236  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_dir = 'models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "train_df, test_df = train_data, test_data\n",
    "\n",
    "age_column = 'age'\n",
    "age_groups = train_df[age_column] // 10 * 10\n",
    "unique_age_groups = age_groups.unique()\n",
    "\n",
    "models = {}\n",
    "feature_importance_matrix = pd.DataFrame()\n",
    "\n",
    "for age_group in unique_age_groups:\n",
    "    group_data = train_df[age_groups == age_group]\n",
    "    \n",
    "    # Select the top 30 features for the current age group\n",
    "    top_features = top_30_features[str(age_group)]\n",
    "    X_train = group_data[top_features]\n",
    "    print(X_train.shape)\n",
    "    y_train = group_data[age_column]\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(interactions=5,greedy_ratio=0,inner_bags=14)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate the training loss\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    \n",
    "    models[age_group] = model\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    print(f\"Age Group: {age_group}-{age_group+9}, MSE: {mse}, Model saved as: {model_filename}\")\n",
    "\n",
    "    # Save feature importances\n",
    "    feature_importance = model.explain_global().data()\n",
    "    feature_importance_df = pd.DataFrame(feature_importance['scores'][:30], columns=[f'Age Group {age_group}'])\n",
    "    feature_importance_matrix = pd.concat([feature_importance_matrix, feature_importance_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Print the feature importance matrix\n",
    "print(feature_importance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e6b5e6-ad18-465f-9f32-82de4c0fed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (MSE) on Test Data: 2.1296\n",
      "Mean Absolute Error (MAE) on Test Data: 1.5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wzp07\\anaconda3\\envs\\AgePrediction\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import faiss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "train_data = train_df\n",
    "test_data = test_df\n",
    "# Load the top 30 features for each age group\n",
    "top_30_features = pd.read_csv('top_30_features_all_age_group.csv', index_col=0).to_dict(orient='list')\n",
    "\n",
    "# Ensure the age group keys are strings\n",
    "top_30_features = {str(key): value for key, value in top_30_features.items()}\n",
    "\n",
    "# Define function to convert age to age group\n",
    "def age_to_group(age):\n",
    "    return str((age // 10) * 10)\n",
    "\n",
    "# Convert ages to age groups\n",
    "train_data['age_group'] = train_data['age'].apply(age_to_group)\n",
    "test_data['age_group'] = test_data['age'].apply(age_to_group)\n",
    "\n",
    "# Prepare Train and Test Data using top 30 features\n",
    "def prepare_data(data, top_features):\n",
    "    age_groups = data['age_group']\n",
    "    X = []\n",
    "    y = []\n",
    "    for age_group in age_groups.unique():\n",
    "        group_data = data[age_groups == age_group]\n",
    "        features = top_features[age_group]\n",
    "        X.append(group_data[features].to_numpy(dtype=np.float32))\n",
    "        y.append(group_data['age_group'].to_numpy())\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "X_train, y_train = prepare_data(train_df, top_30_features)\n",
    "X_test, y_test = prepare_data(test_df, top_30_features)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = X_train.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance for KNN\n",
    "\n",
    "# Train FAISS index\n",
    "index.add(X_train)\n",
    "\n",
    "# KNN search for Test Data\n",
    "k = 11  # Number of neighbors\n",
    "D, I = index.search(X_test, k)  # D is the distances, I is the indices of the nearest neighbors\n",
    "\n",
    "# Predict age group by majority vote of nearest neighbors\n",
    "predicted_age_groups = []\n",
    "for neighbors in I:\n",
    "    neighbor_labels = y_train[neighbors]\n",
    "    unique, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "    predicted_age_groups.append(str(unique[np.argmax(counts)]))\n",
    "\n",
    "# Load the saved models\n",
    "model_save_dir = 'models'\n",
    "age_group_models = {}\n",
    "age_groups = ['0.0', '10.0', '20.0', '30.0', '40.0', '50.0', '60.0', '70.0', '80.0', '90.0', '100.0']\n",
    "\n",
    "for age_group in age_groups:\n",
    "    model_filename = os.path.join(model_save_dir, f'Ideal_EBM_model_age_group_{age_group}.joblib')\n",
    "    if os.path.exists(model_filename):\n",
    "        age_group_models[age_group] = joblib.load(model_filename)\n",
    "\n",
    "# Use the predicted age group to load the corresponding model and make final predictions\n",
    "final_predictions = []\n",
    "for i, age_group in enumerate(predicted_age_groups):\n",
    "    if age_group in age_group_models:\n",
    "        model = age_group_models[age_group]\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        prediction = model.predict(test_sample)[0]\n",
    "        final_predictions.append(prediction)\n",
    "    else:\n",
    "        final_predictions.append(np.nan)  # Handle cases where there is no model for the predicted age group\n",
    "\n",
    "# Calculate errors\n",
    "y_true = test_data['age'].to_numpy(dtype=np.float32)\n",
    "y_pred = np.array(final_predictions)\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred, squared=True)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (MSE) on Test Data: {mse**0.5:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) on Test Data: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5858e-345d-407e-882f-bc65f682943f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a191f6a-bec7-4b03-a995-b8237cc02fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741aa627-fa61-47de-aa2d-b5d7e34db14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30ac69-09fd-458e-9a32-7d9aaef71d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312f24e-441b-459b-b447-f78eff4adc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
